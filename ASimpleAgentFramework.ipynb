{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "KEYrzG2vB8Ip"
      },
      "outputs": [],
      "source": [
        "# Install the required packages using pip in your python environment.\n",
        "#!pip install litellm\n",
        "#!pip install python-dotenv\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()  # Loads variables from .env into environment\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "if not api_key:\n",
        "    raise ValueError(\"OPENAI_API_KEY not found in .env file.\")\n",
        "os.environ['OPENAI_API_KEY'] = api_key     # <---- Reference your OpenAI API key here\n",
        "\n",
        "# There are python files as examples in the /SamplePy directory.\n",
        "# There are sample data files in the /SampleData directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mwe2eeOQB0cC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "import traceback\n",
        "import inspect\n",
        "from litellm import completion\n",
        "from dataclasses import dataclass, field\n",
        "from typing import get_type_hints, List, Callable, Dict, Any\n",
        "\n",
        "tools = {}\n",
        "tools_by_tag = {}\n",
        "\n",
        "def to_openai_tools(tools_metadata: List[dict]): #function to convert tools metadata to OpenAI function calling format\n",
        "    openai_tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": t['tool_name'],\n",
        "                # Include up to 1024 characters of the description\n",
        "                \"description\": t.get('description',\"\")[:1024],\n",
        "                \"parameters\": t.get('parameters',{}),\n",
        "            },\n",
        "        } for t in tools_metadata\n",
        "    ]\n",
        "    return openai_tools\n",
        "\n",
        "def get_tool_metadata(func, tool_name=None, description=None, parameters_override=None, terminal=False, tags=None): #function to extract metadata for a decorator-function to use in tool registration\n",
        "    \"\"\"\n",
        "    Extracts metadata for a function to use in tool registration.\n",
        "\n",
        "    Parameters:\n",
        "        func (function): The function to extract metadata from.\n",
        "        tool_name (str, optional): The name of the tool. Defaults to the function name.\n",
        "        description (str, optional): Description of the tool. Defaults to the function's docstring.\n",
        "        parameters_override (dict, optional): Override for the argument schema. Defaults to dynamically inferred schema.\n",
        "        terminal (bool, optional): Whether the tool is terminal. Defaults to False.\n",
        "        tags (List[str], optional): List of tags to associate with the tool.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing metadata about the tool, including description, args schema, and the function.\n",
        "    \"\"\"\n",
        "    # Default tool_name to the function name if not provided\n",
        "    tool_name = tool_name or func.__name__\n",
        "\n",
        "    # Default description to the function's docstring if not provided\n",
        "    description = description or (func.__doc__.strip() if func.__doc__ else \"No description provided.\")\n",
        "\n",
        "    # Discover the function's signature and type hints if no args_override is provided\n",
        "    if parameters_override is None:\n",
        "        signature = inspect.signature(func)\n",
        "        type_hints = get_type_hints(func)\n",
        "\n",
        "        # Build the arguments schema dynamically\n",
        "        args_schema = {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {},\n",
        "            \"required\": []\n",
        "        }\n",
        "        for param_name, param in signature.parameters.items():\n",
        "\n",
        "            if param_name in [\"action_context\", \"action_agent\"]:\n",
        "                continue  # Skip these parameters\n",
        "\n",
        "            def get_json_type(param_type):\n",
        "                if param_type == str:\n",
        "                    return \"string\"\n",
        "                elif param_type == int:\n",
        "                    return \"integer\"\n",
        "                elif param_type == float:\n",
        "                    return \"number\"\n",
        "                elif param_type == bool:\n",
        "                    return \"boolean\"\n",
        "                elif param_type == list:\n",
        "                    return \"array\"\n",
        "                elif param_type == dict:\n",
        "                    return \"object\"\n",
        "                else:\n",
        "                    return \"string\"\n",
        "\n",
        "            # Add parameter details\n",
        "            param_type = type_hints.get(param_name, str)  # Default to string if type is not annotated\n",
        "            param_schema = {\"type\": get_json_type(param_type)}  # Convert Python types to JSON schema types\n",
        "\n",
        "            args_schema[\"properties\"][param_name] = param_schema\n",
        "\n",
        "            # Add to required if not defaulted\n",
        "            if param.default == inspect.Parameter.empty:\n",
        "                args_schema[\"required\"].append(param_name)\n",
        "    else:\n",
        "        args_schema = parameters_override\n",
        "\n",
        "    # Return the metadata as a dictionary\n",
        "    return {\n",
        "        \"tool_name\": tool_name,\n",
        "        \"description\": description,\n",
        "        \"parameters\": args_schema,\n",
        "        \"function\": func,\n",
        "        \"terminal\": terminal,\n",
        "        \"tags\": tags or []\n",
        "    }\n",
        "\n",
        "\n",
        "def register_tool(tool_name=None, description=None, parameters_override=None, terminal=False, tags=None):\n",
        "    \"\"\"\n",
        "    A decorator to dynamically register a function in the tools dictionary with its parameters, schema, and docstring.\n",
        "\n",
        "    Parameters:\n",
        "        tool_name (str, optional): The name of the tool to register. Defaults to the function name.\n",
        "        description (str, optional): Override for the tool's description. Defaults to the function's docstring.\n",
        "        parameters_override (dict, optional): Override for the argument schema. Defaults to dynamically inferred schema.\n",
        "        terminal (bool, optional): Whether the tool is terminal. Defaults to False.\n",
        "        tags (List[str], optional): List of tags to associate with the tool.\n",
        "\n",
        "    Returns:\n",
        "        function: The wrapped function.\n",
        "    \"\"\"\n",
        "    def decorator(func):\n",
        "        # Use the reusable function to extract metadata\n",
        "        metadata = get_tool_metadata(\n",
        "            func=func,\n",
        "            tool_name=tool_name,\n",
        "            description=description,\n",
        "            parameters_override=parameters_override,\n",
        "            terminal=terminal,\n",
        "            tags=tags\n",
        "        )\n",
        "\n",
        "        # Register the tool in the global dictionary\n",
        "        tools[metadata[\"tool_name\"]] = {\n",
        "            \"description\": metadata[\"description\"],\n",
        "            \"parameters\": metadata[\"parameters\"],\n",
        "            \"function\": metadata[\"function\"],\n",
        "            \"terminal\": metadata[\"terminal\"],\n",
        "            \"tags\": metadata[\"tags\"] or []\n",
        "        }\n",
        "\n",
        "        for tag in metadata[\"tags\"]:\n",
        "            if tag not in tools_by_tag:\n",
        "                tools_by_tag[tag] = []\n",
        "            tools_by_tag[tag].append(metadata[\"tool_name\"])\n",
        "\n",
        "        return func\n",
        "    return decorator\n",
        "\n",
        "@dataclass # Prompt class to hold messages, tools, and metadata\n",
        "class Prompt:\n",
        "    messages: List[Dict] = field(default_factory=list)\n",
        "    tools: List[Dict] = field(default_factory=list)\n",
        "    metadata: dict = field(default_factory=dict)  # Fixing mutable default issue\n",
        "\n",
        "\n",
        "def generate_response(prompt: Prompt) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "\n",
        "    messages = prompt.messages\n",
        "    tools = prompt.tools\n",
        "\n",
        "    result = None\n",
        "\n",
        "    if not tools:\n",
        "        response = completion(\n",
        "            model=\"openai/gpt-4o\",\n",
        "            messages=messages,\n",
        "            max_tokens=1024\n",
        "        )\n",
        "        result = response.choices[0].message.content\n",
        "    else:\n",
        "        response = completion(\n",
        "            model=\"openai/gpt-4o\",\n",
        "            messages=messages,\n",
        "            tools=tools,\n",
        "            max_tokens=1024\n",
        "        )\n",
        "\n",
        "        if response.choices[0].message.tool_calls:\n",
        "            tool = response.choices[0].message.tool_calls[0]\n",
        "            result = {\n",
        "                \"tool\": tool.function.name,\n",
        "                \"args\": json.loads(tool.function.arguments),\n",
        "            }\n",
        "            result = json.dumps(result)\n",
        "        else:\n",
        "            result = response.choices[0].message.content\n",
        "\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "@dataclass(frozen=True) # Goal class to represent a goal with priority, name, and description\n",
        "class Goal:\n",
        "    priority: int\n",
        "    name: str\n",
        "    description: str\n",
        "\n",
        "\n",
        "class Action: # Action class to represent an action with a name, function, description, parameters, and terminal status\n",
        "    def __init__(self,\n",
        "                 name: str,\n",
        "                 function: Callable,\n",
        "                 description: str,\n",
        "                 parameters: Dict,\n",
        "                 terminal: bool = False):\n",
        "        self.name = name\n",
        "        self.function = function\n",
        "        self.description = description\n",
        "        self.terminal = terminal\n",
        "        self.parameters = parameters\n",
        "\n",
        "    def execute(self, **args) -> Any:\n",
        "        \"\"\"Execute the action's function\"\"\"\n",
        "        return self.function(**args)\n",
        "\n",
        "\n",
        "class ActionRegistry: # ActionRegistry class to hold and manage actions\n",
        "    def __init__(self):\n",
        "        self.actions = {}\n",
        "\n",
        "    def register(self, action: Action):\n",
        "        self.actions[action.name] = action\n",
        "\n",
        "    def get_action(self, name: str) -> [Action, None]:\n",
        "        return self.actions.get(name, None)\n",
        "\n",
        "    def get_actions(self) -> List[Action]:\n",
        "        \"\"\"Get all registered actions\"\"\"\n",
        "        return list(self.actions.values())\n",
        "\n",
        "\n",
        "class Memory: # Memory class to hold conversation history\n",
        "    def __init__(self):\n",
        "        self.items = []  # Basic conversation history\n",
        "\n",
        "    def add_memory(self, memory: dict):\n",
        "        \"\"\"Add memory to working memory\"\"\"\n",
        "        self.items.append(memory)\n",
        "\n",
        "    def get_memories(self, limit: int = None) -> List[Dict]:\n",
        "        \"\"\"Get formatted conversation history for prompt\"\"\"\n",
        "        return self.items[:limit]\n",
        "\n",
        "    def copy_without_system_memories(self):\n",
        "        \"\"\"Return a copy of the memory without system memories\"\"\"\n",
        "        filtered_items = [m for m in self.items if m[\"type\"] != \"system\"]\n",
        "        memory = Memory()\n",
        "        memory.items = filtered_items\n",
        "        return memory\n",
        "\n",
        "\n",
        "class Environment: # Environment class to execute actions and manage results\n",
        "    def execute_action(self, action: Action, args: dict) -> dict: # function to execute an action in the environment\n",
        "        \"\"\"Execute an action and return the result.\"\"\"\n",
        "        try:\n",
        "            result = action.execute(**args)\n",
        "            return self.format_result(result)\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"tool_executed\": False,\n",
        "                \"error\": str(e),\n",
        "                \"traceback\": traceback.format_exc()\n",
        "            }\n",
        "\n",
        "    def format_result(self, result: Any) -> dict: # function to format the result of an action execution\n",
        "        \"\"\"Format the result with metadata.\"\"\"\n",
        "        return {\n",
        "            \"tool_executed\": True,\n",
        "            \"result\": result,\n",
        "            \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
        "        }\n",
        "\n",
        "\n",
        "class AgentLanguage: # Base class for agent languages to define how prompts are constructed and responses are parsed\n",
        "    def __init__(self): # Initialize the agent language\n",
        "        pass\n",
        "\n",
        "    def construct_prompt(self, # Construct a prompt for the agent\n",
        "                         actions: List[Action],\n",
        "                         environment: Environment,\n",
        "                         goals: List[Goal],\n",
        "                         memory: Memory) -> Prompt:\n",
        "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
        "\n",
        "\n",
        "    def parse_response(self, response: str) -> dict:\n",
        "    \"\"\"Parse LLM response into structured format by extracting the ```json block\"\"\"\n",
        "    try:\n",
        "        return json.loads(response)\n",
        "    except Exception as e:\n",
        "        print(\"LLM returned invalid JSON. Raw response:\")\n",
        "        print(response)\n",
        "        # Optionally, log or save the response for further debugging\n",
        "        return {\n",
        "            \"tool\": \"terminate\",\n",
        "            \"args\": {\"message\": f\"LLM returned invalid JSON: {response}\"}\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "class AgentFunctionCallingActionLanguage(AgentLanguage): # AgentLanguage subclass for function calling action language\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def format_goals(self, goals: List[Goal]) -> List:\n",
        "        # Map all goals to a single string that concatenates their description\n",
        "        # and combine into a single message of type system\n",
        "        sep = \"\\n-------------------\\n\"\n",
        "        goal_instructions = \"\\n\\n\".join([f\"{goal.name}:{sep}{goal.description}{sep}\" for goal in goals])\n",
        "        return [\n",
        "            {\"role\": \"system\", \"content\": goal_instructions}\n",
        "        ]\n",
        "\n",
        "    def format_memory(self, memory: Memory) -> List:\n",
        "        \"\"\"Generate response from language model\"\"\"\n",
        "        # Map all environment results to a role:user messages\n",
        "        # Map all assistant messages to a role:assistant messages\n",
        "        # Map all user messages to a role:user messages\n",
        "        items = memory.get_memories()\n",
        "        mapped_items = []\n",
        "        for item in items:\n",
        "\n",
        "            content = item.get(\"content\", None)\n",
        "            if not content:\n",
        "                content = json.dumps(item, indent=4)\n",
        "\n",
        "            if item[\"type\"] == \"assistant\":\n",
        "                mapped_items.append({\"role\": \"assistant\", \"content\": content})\n",
        "            elif item[\"type\"] == \"environment\":\n",
        "                mapped_items.append({\"role\": \"assistant\", \"content\": content})\n",
        "            else:\n",
        "                mapped_items.append({\"role\": \"user\", \"content\": content})\n",
        "\n",
        "        return mapped_items\n",
        "\n",
        "    def format_actions(self, actions: List[Action]) -> [List,List]:\n",
        "        \"\"\"Generate response from language model\"\"\"\n",
        "\n",
        "        tools = [\n",
        "            {\n",
        "                \"type\": \"function\",\n",
        "                \"function\": {\n",
        "                    \"name\": action.name,\n",
        "                    # Include up to 1024 characters of the description\n",
        "                    \"description\": action.description[:1024],\n",
        "                    \"parameters\": action.parameters,\n",
        "                },\n",
        "            } for action in actions\n",
        "        ]\n",
        "\n",
        "        return tools\n",
        "\n",
        "    def construct_prompt(self,  # Construct a prompt for the agent\n",
        "                         actions: List[Action],\n",
        "                         environment: Environment,\n",
        "                         goals: List[Goal],\n",
        "                         memory: Memory) -> Prompt:\n",
        "\n",
        "        prompt = []\n",
        "        prompt += self.format_goals(goals)\n",
        "        prompt += self.format_memory(memory)\n",
        "\n",
        "        tools = self.format_actions(actions)\n",
        "\n",
        "        return Prompt(messages=prompt, tools=tools)\n",
        "\n",
        "    def adapt_prompt_after_parsing_error(self, # Adapt the prompt after a parsing error\n",
        "                                         prompt: Prompt,\n",
        "                                         response: str,\n",
        "                                         traceback: str,\n",
        "                                         error: Any,\n",
        "                                         retries_left: int) -> Prompt:\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def parse_response(self, response: str) -> dict:\n",
        "        \"\"\"Parse LLM response into structured format by extracting the ```json block\"\"\"\n",
        "\n",
        "        try:\n",
        "            return json.loads(response)\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"tool\": \"terminate\",\n",
        "                \"args\": {\"message\":response}\n",
        "            }\n",
        "class PythonActionRegistry(ActionRegistry): # PythonActionRegistry class to hold and manage actions with filtering capabilities\n",
        "    def __init__(self, tags: List[str] = None, tool_names: List[str] = None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.terminate_tool = None\n",
        "\n",
        "        for tool_name, tool_desc in tools.items():\n",
        "            if tool_name == \"terminate\":\n",
        "                self.terminate_tool = tool_desc\n",
        "\n",
        "            if tool_names and tool_name not in tool_names:\n",
        "                continue\n",
        "\n",
        "            tool_tags = tool_desc.get(\"tags\", [])\n",
        "            if tags and not any(tag in tool_tags for tag in tags):\n",
        "                continue\n",
        "\n",
        "            self.register(Action(\n",
        "                name=tool_name,\n",
        "                function=tool_desc[\"function\"],\n",
        "                description=tool_desc[\"description\"],\n",
        "                parameters=tool_desc.get(\"parameters\", {}),\n",
        "                terminal=tool_desc.get(\"terminal\", False)\n",
        "            ))\n",
        "\n",
        "    def register_terminate_tool(self):\n",
        "        if self.terminate_tool:\n",
        "            self.register(Action(\n",
        "                name=\"terminate\",\n",
        "                function=self.terminate_tool[\"function\"],\n",
        "                description=self.terminate_tool[\"description\"],\n",
        "                parameters=self.terminate_tool.get(\"parameters\", {}),\n",
        "                terminal=self.terminate_tool.get(\"terminal\", False)\n",
        "            ))\n",
        "        else:\n",
        "            raise Exception(\"Terminate tool not found in tool registry\")\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self,\n",
        "                 goals: List[Goal],\n",
        "                 agent_language: AgentLanguage,\n",
        "                 action_registry: ActionRegistry,\n",
        "                 generate_response: Callable[[Prompt], str],\n",
        "                 environment: Environment):\n",
        "        \"\"\"\n",
        "        Initialize an agent with its core GAME components\n",
        "        \"\"\"\n",
        "        self.goals = goals\n",
        "        self.generate_response = generate_response\n",
        "        self.agent_language = agent_language\n",
        "        self.actions = action_registry\n",
        "        self.environment = environment\n",
        "\n",
        "    def construct_prompt(self, goals: List[Goal], memory: Memory, actions: ActionRegistry) -> Prompt:\n",
        "        \"\"\"Build prompt with memory context\"\"\"\n",
        "        return self.agent_language.construct_prompt(\n",
        "            actions=actions.get_actions(),\n",
        "            environment=self.environment,\n",
        "            goals=goals,\n",
        "            memory=memory\n",
        "        )\n",
        "\n",
        "    def get_action(self, response):\n",
        "        invocation = self.agent_language.parse_response(response)\n",
        "        action = self.actions.get_action(invocation[\"tool\"])\n",
        "        return action, invocation\n",
        "\n",
        "    def should_terminate(self, response: str) -> bool:\n",
        "        action_def, _ = self.get_action(response)\n",
        "        return action_def.terminal\n",
        "\n",
        "    def set_current_task(self, memory: Memory, task: str):\n",
        "        memory.add_memory({\"type\": \"user\", \"content\": task})\n",
        "\n",
        "    def update_memory(self, memory: Memory, response: str, result: dict):\n",
        "        \"\"\"\n",
        "        Update memory with the agent's decision and the environment's response.\n",
        "        \"\"\"\n",
        "        new_memories = [\n",
        "            {\"type\": \"assistant\", \"content\": response},\n",
        "            {\"type\": \"environment\", \"content\": json.dumps(result)}\n",
        "        ]\n",
        "        for m in new_memories:\n",
        "            memory.add_memory(m)\n",
        "\n",
        "    def prompt_llm_for_action(self, full_prompt: Prompt) -> str:\n",
        "        response = self.generate_response(full_prompt)\n",
        "        return response\n",
        "\n",
        "    def run(self, user_input: str, memory=None, max_iterations: int = 50) -> Memory:\n",
        "        \"\"\"\n",
        "        Execute the GAME loop for this agent with a maximum iteration limit.\n",
        "        \"\"\"\n",
        "        memory = memory or Memory()\n",
        "        self.set_current_task(memory, user_input)\n",
        "\n",
        "        for _ in range(max_iterations):\n",
        "            # Construct a prompt that includes the Goals, Actions, and the current Memory\n",
        "            prompt = self.construct_prompt(self.goals, memory, self.actions)\n",
        "\n",
        "            print(\"Agent thinking...\")\n",
        "            # Generate a response from the agent\n",
        "            response = self.prompt_llm_for_action(prompt)\n",
        "            print(f\"Agent Decision: {response}\")\n",
        "\n",
        "            # Determine which action the agent wants to execute\n",
        "            action, invocation = self.get_action(response)\n",
        "\n",
        "            # Execute the action in the environment\n",
        "            result = self.environment.execute_action(action, invocation[\"args\"])\n",
        "            print(f\"Action Result: {result}\")\n",
        "\n",
        "            # Update the agent's memory with information about what happened\n",
        "            self.update_memory(memory, response, result)\n",
        "\n",
        "            # Check if the agent has decided to terminate\n",
        "            if self.should_terminate(response):\n",
        "                break\n",
        "\n",
        "        return memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PC3ncxezoJC",
        "outputId": "564b75ed-bcc3-4f59-c51f-ed4e39d7bf90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent thinking...\n",
            "Agent Decision: {\"tool\": \"list_all_python_files\", \"args\": {}}\n",
            "Action Result: {'tool_executed': True, 'result': ['./SamplePy/NormalizeCountries.py', './SamplePy/analyze_import2.py', './SamplePy/database_operations.py', './SamplePy/wars_barchartrace.py'], 'timestamp': '2025-06-30T19:36:47+0200'}\n",
            "Agent thinking...\n",
            "Agent Decision: {\"tool\": \"read_project_file\", \"args\": {\"name\": \"./SamplePy/NormalizeCountries.py\"}}\n",
            "Action Result: {'tool_executed': True, 'result': 'import re\\nfrom database_operations import get_all_participants # Import database functions\\nfrom mapping import kriegsteilnehmer_mapping_red #import mapping table from a separate module\\nimport pandas as pd\\nimport numpy as np\\n\\n\\ndef process_country_list(country_list_string, mapping_table):\\n    \"\"\"\\n    Processes a single string containing a list of countries and maps them\\n    to the keys in the provided mapping table.\\n\\n    Args:\\n        country_list_string (str): The string from your database column (e.g., \"Alliierte (USA,Großbritannien,Kanada,Freie Französische Streitkräfte,Polen u.a.)\").\\n        mapping_table (dict): The mapping table (kriegsteilnehmer_mapping_red).\\n\\n    Returns:\\n        list: A list of mapped \"canonical\" country names (keys from the mapping table)\\n              found in the input string.\\n    \"\"\"\\n    mapped_countries = set()\\n\\n    # 1. Extract individual country names from the string\\n    # This regex tries to capture names that are separated by commas,\\n    # or inside parentheses. It\\'s a bit robust.\\n    # It also handles \"u.a.\" by ignoring it.\\n    extracted_countries = re.findall(r\\'[\\\\w\\\\säöüÄÖÜß\\\\.-]+\\', country_list_string)\\n    # Filter out common separators or indicators that aren\\'t country names\\n    extracted_countries = [\\n        country.strip() for country in extracted_countries\\n        if country.strip() and country.strip().lower() not in [\"u.a.\", \"\"]\\n    ]\\n    # Further refinement for parenthetical content\\n    if \\'(\\' in country_list_string and \\')\\' in country_list_string:\\n        parenthetical_content = re.search(r\\'\\\\((.*?)\\\\)\\', country_list_string)\\n        if parenthetical_content:\\n            inner_countries = [c.strip() for c in parenthetical_content.group(1).split(\\',\\')]\\n            extracted_countries.extend(inner_countries)\\n    # Remove duplicates and refine the list\\n    extracted_countries = list(set([re.sub(r\\'\\\\s*\\\\(.*\\\\)\\\\s*\\', \\'\\', c).strip() for c in extracted_countries]))\\n    extracted_countries = [c for c in extracted_countries if c] # Remove empty strings\\n\\n\\n    # 2. Iterate through your mapping table to find matches\\n    for canonical_name, aliases_str in mapping_table.items():\\n        aliases = [alias.strip() for alias in aliases_str.split(\\',\\')]\\n        for extracted in extracted_countries:\\n            if extracted in aliases:\\n                mapped_countries.add(canonical_name)\\n                break # Once a match is found for this canonical name, move to the next one\\n\\n    return list(mapped_countries)\\n\\n# Example usage with your provided database strings:\\n#print(\"Before shape\")\\ndb_aggressors = get_all_participants(\\'Parteien_Seite_Aggressor\\')  # Assuming this function returns a list of strings from your database\\ndb_defenders = get_all_participants(\\'Parteien_Seite_Verteidiger\\')  # Assuming this function returns a list of strings from your database\\n#print(db_strings.head())  # Display the first few rows of the DataFrame\\n#print(\"After shape\")\\n#print(df.head()) #DEBUG first 5 rows\\n\\n# Start with the original DataFrame (e.g. db_aggressors)\\ndf = db_aggressors.copy()\\n\\n# Map aggressors\\ndf[\\'mapped_Parteien_Seite_Aggressor\\'] = df[\\'Parteien_Seite_Aggressor\\'].apply(lambda x: process_country_list(x, kriegsteilnehmer_mapping_red))\\nfor idx, mapped_list in df[\\'mapped_Parteien_Seite_Aggressor\\'].items():\\n    for country in mapped_list:\\n        df.at[idx, country] = \\'Agressor\\'\\n\\n# Map defenders (use the same DataFrame!)\\ndf[\\'mapped_Parteien_Seite_Verteidiger\\'] = db_defenders[\\'Parteien_Seite_Verteidiger\\'].apply(lambda x: process_country_list(x, kriegsteilnehmer_mapping_red))\\nfor idx, mapped_list in df[\\'mapped_Parteien_Seite_Verteidiger\\'].items():\\n    for country in mapped_list:\\n        # Create the column if it does not exist\\n        if country not in df.columns:\\n            df[country] = np.nan\\n        # If already \\'Agressor\\', set to \\'Both\\', else \\'Defender\\'\\n        if df.at[idx, country] == \\'Agressor\\':\\n            df.at[idx, country] = \\'Both\\'\\n        else:\\n            df.at[idx, country] = \\'Defender\\'\\n\\n# Optional: fill NaN with False for all new columns (canonical country names)\\n#country_columns = set([country for sublist in df[\\'mapped_Parteien_Seite_Aggressor\\'] for country in sublist])\\n#df[list(country_columns)] = df[list(country_columns)].fillna(False)\\n\\n# Save the DataFrame to a CSV file\\n#df.to_csv(\"normalized_participants.csv\", index=False)\\n\\n# Open a connection to your existing database\\n# Convert lists to comma-separated strings for database storage\\ndf[\\'mapped_Parteien_Seite_Aggressor\\'] = df[\\'mapped_Parteien_Seite_Aggressor\\'].apply(lambda x: \\', \\'.join(x) if isinstance(x, list) else str(x))\\ndf[\\'mapped_Parteien_Seite_Verteidiger\\'] = df[\\'mapped_Parteien_Seite_Verteidiger\\'].apply(lambda x: \\', \\'.join(x) if isinstance(x, list) else str(x))\\nimport sqlite3\\nconn = sqlite3.connect(\\'kriege_datenbank.db\\')\\n# Write the DataFrame to a new table, e.g. \"normalized_participants\"\\ndf.to_sql(\\'KriegeGlobalTeilnehmer\\', conn, if_exists=\\'replace\\', index=False)\\nconn.close()\\n\\n\\n\\n\\n\\n# After both loops for aggressor and defender, collect all country columns\\n# (they are the columns that are not in the original db_defenders columns or mapped columns)\\noriginal_columns = set(db_defenders.columns) | {\\'mapped_Parteien_Seite_Aggressor\\', \\'mapped_Parteien_Seite_Verteidiger\\'}\\ncountry_columns = [col for col in df.columns if col not in original_columns]\\n\\nfrom itertools import permutations\\n\\nmax_count = 0\\nmax_pair = (None, None)\\n\\nfor country1, country2 in permutations(country_columns, 2):\\n    # country1 ist Aggressor, country2 ist Defender in derselben Zeile\\n    count = ((df[country1] == \\'Agressor\\') & (df[country2] == \\'Defender\\')).sum()\\n    if count > max_count:\\n        max_count = count\\n        max_pair = (country1, country2)\\n\\nprint(f\"The pair of countries most often on different sides (Aggressor/Defender): {max_pair} ({max_count} rows)\")\\n\\n# Zähle für jedes Land, wie oft es \"Agressor\" oder \"Defender\" ist\\naggressor_counts = {}\\ndefender_counts = {}\\n\\nfor country in country_columns:\\n    aggressor_counts[country] = (df[country] == \\'Agressor\\').sum()\\n    defender_counts[country] = (df[country] == \\'Defender\\').sum()\\n\\n# Finde das Land mit den meisten \"Agressor\"- und \"Defender\"-Einträgen\\nmost_aggressor = max(aggressor_counts, key=aggressor_counts.get)\\nmost_defender = max(defender_counts, key=defender_counts.get)\\n\\nprint(f\"Most frequent Aggressor: {most_aggressor} ({aggressor_counts[most_aggressor]} times)\")\\nprint(f\"Most frequent Defender: {most_defender} ({defender_counts[most_defender]} times)\")\\n\\nboth_counts = {}\\n\\nfor country in country_columns:\\n    both_counts[country] = aggressor_counts[country] + defender_counts[country]\\n\\nmost_both = max(both_counts, key=both_counts.get)\\nprint(f\"Country most often involved as both Aggressor and Defender: {most_both} ({both_counts[most_both]} times)\")\\n\\n\\nboth_role_counts = {}\\n\\nfor country in country_columns:\\n    both_role_counts[country] = (df[country] == \\'Both\\').sum()\\n\\n# Sort and print the results\\nfor country, count in sorted(both_role_counts.items(), key=lambda x: x[1], reverse=True):\\n    if count > 0:\\n        print(f\"{country}: {count} times as Both\")\\n\\n\\n# Bar_chart_race Kriegsteilnahmen\\n# 1. Wähle die relevanten Spalten aus\\n# Annahme: \\'Startjahr\\' ist numerisch, country_columns enthält alle Länder-Spalten\\ndf_bcr = df[[\\'Startjahr\\'] + country_columns].copy()\\n\\n# 2. Ersetze alle Nicht-NaN-Werte durch 1 (Beteiligung), sonst 0\\nfor country in country_columns:\\n    df_bcr[country] = df_bcr[country].notna().astype(int)\\n\\n# 3. Gruppiere nach Jahr und summiere die Beteiligungen\\ndf_bcr_grouped = df_bcr.groupby(\\'Startjahr\\')[country_columns].sum()\\ndf_bcr_cumulative = df_bcr_grouped.cumsum()\\n\\n# Optional: Sortiere die Jahre aufsteigend\\ndf_bcr_cumulative = df_bcr_cumulative.sort_index()\\n\\n# 4. Speichere das Ergebnis für bar_chart_race\\ndf_bcr_cumulative.to_csv(\"barchartrace_countries_by_year.csv\")\\n\\n#print(df_bcr_grouped.head())\\n\\n\\n\\n# Bar_chart_race Kriegsopferzahlen\\n# 1. Prepare a DataFrame with Startjahr, Opferzahlen_Gesamt_bis, and country columns\\ndf_opfer = df[[\\'Startjahr\\', \\'Opferzahlen_Gesamt_bis\\'] + country_columns].copy()\\n\\n# 2. For each country, set value to Opferzahlen_Gesamt_bis if participating, else 0\\nfor country in country_columns:\\n    df_opfer[country] = df_opfer[country].notna().astype(int) * df_opfer[\\'Opferzahlen_Gesamt_bis\\'].fillna(0)\\n\\n# 3. Group by year and sum\\ndf_opfer_grouped = df_opfer.groupby(\\'Startjahr\\')[country_columns].sum()\\n\\n# 4. Cumulative sum over years\\ndf_opfer_cumulative = df_opfer_grouped.cumsum().sort_index()\\n\\n# 5. Save for bar_chart_race\\ndf_opfer_cumulative.to_csv(\"barchartrace_countries_by_opferzahlen.csv\")\\n#print(df_opfer_cumulative.head())', 'timestamp': '2025-06-30T19:36:48+0200'}\n",
            "Agent thinking...\n",
            "Agent Decision: {\"tool\": \"read_project_file\", \"args\": {\"name\": \"./SamplePy/analyze_import2.py\"}}\n",
            "Action Result: {'tool_executed': True, 'result': 'import csv\\nimport sqlite3\\nfrom collections import Counter # Um Duplikate leicht zu zählen\\n\\n# --- Konfiguration ---\\nCSV_FILE_PATH = \\'China.csv\\'\\nDB_FILE_PATH = \\'kriege_datenbank.db\\'\\nTABLE_NAME = \\'KriegeChina\\'\\nCSV_KRIEG_COLUMN_INDEX = 0\\nDB_KRIEG_COLUMN_NAME = \\'Krieg\\'\\nEXPECTED_COLUMNS_IN_DATA = 14 # Die Anzahl der Spalten in deinen Datenzeilen\\n\\ndef compare_csv_and_db_wars():\\n    csv_war_list_all = [] # Liste aller Kriegsnamen aus der CSV\\n    csv_skipped_rows = 0\\n\\n    print(f\"Lese Kriege aus CSV-Datei: {CSV_FILE_PATH}\")\\n    try:\\n        with open(CSV_FILE_PATH, mode=\\'r\\', encoding=\\'utf-8-sig\\') as csvfile:\\n            csv_reader = csv.reader(csvfile)\\n            header = next(csv_reader)\\n\\n            for i, row in enumerate(csv_reader):\\n                current_row_num_in_file = i + 2\\n                if not any(field.strip() for field in row):\\n                    csv_skipped_rows +=1\\n                    continue\\n                if len(row) != EXPECTED_COLUMNS_IN_DATA:\\n                    print(f\"Info CSV: Zeile {current_row_num_in_file} hat {len(row)} Spalten, erwartet {EXPECTED_COLUMNS_IN_DATA}. Übersprungen für diesen Vergleich.\")\\n                    csv_skipped_rows +=1\\n                    continue\\n                try:\\n                    war_name = row[CSV_KRIEG_COLUMN_INDEX].strip()\\n                    if war_name: # Nur hinzufügen, wenn der Name nicht leer ist\\n                        csv_war_list_all.append(war_name)\\n                    else:\\n                        print(f\"Info CSV: Kriegsname in Zeile {current_row_num_in_file} ist leer.\")\\n                        csv_skipped_rows +=1\\n                except IndexError:\\n                    print(f\"Fehler CSV: Zeile {current_row_num_in_file} hat nicht genügend Spalten für Kriegsnamen.\")\\n                    csv_skipped_rows +=1\\n                    continue\\n    except FileNotFoundError:\\n        print(f\"Fehler: CSV-Datei \\'{CSV_FILE_PATH}\\' nicht gefunden.\")\\n        return\\n    except Exception as e:\\n        print(f\"Fehler beim Lesen der CSV: {e}\")\\n        return\\n\\n    print(f\"{len(csv_war_list_all)} Kriege (potenziell mit Duplikaten) aus CSV geladen (nach Überspringen von {csv_skipped_rows} Zeilen).\")\\n\\n    # Zähle Duplikate in der CSV\\n    csv_war_counts = Counter(csv_war_list_all)\\n    csv_unique_wars_set = set(csv_war_list_all)\\n    csv_duplicate_names = {name: count for name, count in csv_war_counts.items() if count > 1}\\n\\n    print(f\"{len(csv_unique_wars_set)} einzigartige Kriegsnamen in der CSV-Liste.\")\\n    if csv_duplicate_names:\\n        print(f\"{len(csv_duplicate_names)} Kriegsname(n) kommen in der CSV mehrfach vor:\")\\n        for name, count in csv_duplicate_names.items():\\n            print(f\"  - \\'{name}\\' (kommt {count} Mal vor)\")\\n    else:\\n        print(\"Keine Duplikate (basierend auf Kriegsnamen) in der CSV-Liste gefunden.\")\\n\\n    # --- Aus der Datenbank lesen ---\\n    db_war_list_all = []\\n    db_row_count_actual = 0\\n    conn_db_count = None\\n    try:\\n        conn_db_count = sqlite3.connect(DB_FILE_PATH)\\n        cursor_db_count = conn_db_count.cursor()\\n        # Tatsächliche Zeilenzahl ermitteln\\n        cursor_db_count.execute(f\"SELECT COUNT(*) FROM {TABLE_NAME}\")\\n        db_row_count_actual = cursor_db_count.fetchone()[0]\\n\\n        # Alle Kriegsnamen aus der DB holen\\n        cursor_db_count.execute(f\"SELECT \\\\\"{DB_KRIEG_COLUMN_NAME}\\\\\" FROM {TABLE_NAME}\")\\n        for row in cursor_db_count:\\n            if row[0] is not None: # Ignoriere NULL-Werte für den Kriegsnamen, falls vorhanden\\n                 db_war_list_all.append(row[0].strip())\\n            else:\\n                print(\"Info DB: Ein Kriegsname in der DB ist NULL.\")\\n        conn_db_count.close()\\n    except sqlite3.Error as e:\\n        print(f\"SQLite Fehler beim Lesen der DB: {e}\")\\n        if conn_db_count: conn_db_count.close()\\n        return\\n\\n    print(f\"\\\\nDatenbank-Analyse:\")\\n    print(f\"Tatsächliche Zeilenanzahl in DB-Tabelle \\'{TABLE_NAME}\\' laut COUNT(*): {db_row_count_actual}\")\\n    print(f\"{len(db_war_list_all)} Kriegsnamen aus DB geladen (nach .strip() und ohne NULLs).\")\\n\\n    db_war_counts = Counter(db_war_list_all)\\n    db_unique_wars_set = set(db_war_list_all)\\n    db_duplicate_names = {name: count for name, count in db_war_counts.items() if count > 1}\\n\\n    print(f\"{len(db_unique_wars_set)} einzigartige Kriegsnamen in der DB-Liste (nach .strip()).\")\\n    if db_duplicate_names:\\n        print(f\"ACHTUNG: {len(db_duplicate_names)} Kriegsname(n) kommen in der DB-Liste MEHRFACH vor (sollte bei PRIMARY KEY nicht sein, es sei denn .strip() führt zu Kollisionen):\")\\n        for name, count in db_duplicate_names.items():\\n            print(f\"  - \\'{name}\\' (kommt {count} Mal vor in der DB-Liste nach .strip())\")\\n    else:\\n        print(\"Keine Duplikate in der DB-Liste der Kriegsnamen gefunden (nach .strip()).\")\\n\\n\\n    # --- Vergleiche die Sets ---\\n    print(\"\\\\nVergleich der einzigartigen Kriegsnamen-Sets:\")\\n    missing_in_db_set = csv_unique_wars_set - db_unique_wars_set\\n    missing_in_csv_set = db_unique_wars_set - csv_unique_wars_set\\n\\n    if missing_in_db_set:\\n        print(f\"\\\\n{len(missing_in_db_set)} EINZIGARTIGE Kriege sind im CSV-Set, aber NICHT im DB-Set:\")\\n        for war in sorted(list(missing_in_db_set)):\\n            print(f\"  - \\'{war}\\'\")\\n    else:\\n        print(\"\\\\nAlle einzigartigen Kriege aus dem CSV-Set sind auch im DB-Set vorhanden.\")\\n\\n    if missing_in_csv_set:\\n        print(f\"\\\\n{len(missing_in_csv_set)} EINZIGARTIGE Kriege sind im DB-Set, aber NICHT im CSV-Set (sollte nicht passieren, wenn CSV die Quelle ist):\")\\n        for war in sorted(list(missing_in_csv_set)):\\n            print(f\"  - \\'{war}\\'\")\\n    else:\\n        print(\"\\\\nAlle einzigartigen Kriege aus dem DB-Set sind auch im CSV-Set vorhanden.\")\\n\\n    print(\"\\\\n--- Zusammenfassung der Zählungen ---\")\\n    print(f\"CSV: {len(csv_war_list_all)} gelesene Namen (potenziell mit Duplikaten)\")\\n    print(f\"CSV: {len(csv_unique_wars_set)} einzigartige Namen\")\\n    print(f\"DB (COUNT(*)): {db_row_count_actual} Zeilen\")\\n    print(f\"DB: {len(db_war_list_all)} gelesene Namen (ignoriert NULLs, .strip() angewendet)\")\\n    print(f\"DB: {len(db_unique_wars_set)} einzigartige Namen (nach .strip())\")\\n\\n    if len(csv_unique_wars_set) == db_row_count_actual and not missing_in_db_set and not missing_in_csv_set and not csv_duplicate_names:\\n        print(\"\\\\nPerfekte Übereinstimmung zwischen einzigartigen CSV-Namen und DB-Zeilenanzahl, keine Duplikate in CSV.\")\\n    elif len(csv_war_list_all) - len(csv_duplicate_names) == db_row_count_actual and not missing_in_db_set and not missing_in_csv_set :\\n         # Diese Logik ist nicht ganz korrekt, wenn csv_duplicate_names die Anzahl der Namen ist, nicht die Anzahl der Duplikat-Instanzen\\n         num_lost_to_duplicates = sum(count - 1 for count in csv_duplicate_names.values())\\n         if len(csv_war_list_all) - num_lost_to_duplicates == db_row_count_actual:\\n            print(f\"\\\\nDie Differenz zwischen CSV-Rohdaten ({len(csv_war_list_all)}) und DB-Zeilen ({db_row_count_actual}) scheint durch {num_lost_to_duplicates} Duplikat-Instanzen in der CSV erklärt zu werden.\")\\n\\n\\nif __name__ == \\'__main__\\':\\n    compare_csv_and_db_wars()', 'timestamp': '2025-06-30T19:36:53+0200'}\n",
            "Agent thinking...\n",
            "Agent Decision: {\"tool\": \"read_project_file\", \"args\": {\"name\": \"./SamplePy/database_operations.py\"}}\n",
            "Action Result: {'tool_executed': True, 'result': 'import sqlite3\\nimport pandas as pd\\n\\ndef reset_database(table):\\n    conn = sqlite3.connect(\"kriege_datenbank.db\")\\n    cursor = conn.cursor()\\n    \\n    # Lösche die Tabelle, falls sie existiert\\n    cursor.execute(\"DROP TABLE IF EXISTS table\")\\n    \\n    # Erstelle die Tabelle neu\\n    cursor.execute(\"\"\"\\n        CREATE TABLE table (\\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\\n            Krieg_Name TEXT NOT NULL,\\n            Start_Jahr INTEGER,\\n            End_Jahr INTEGER\\n        )\\n    \"\"\")\\n    \\n    conn.commit()\\n    conn.close()\\n\\ndef delete_duplicates_from_wars():\\n    conn = sqlite3.connect(\"kriege_datenbank.db\")\\n    cursor = conn.cursor()\\n\\n    # Lösche Duplikate basierend auf name, Start_Jahr und End_Jahr\\n    cursor.execute(\"\"\"\\n        DELETE FROM kriege\\n        WHERE rowid NOT IN (\\n            SELECT MIN(rowid)\\n            FROM kriege\\n            GROUP BY Krieg_Name, Start_Jahr, End_Jahr\\n        )\\n    \"\"\")\\n    conn.commit()\\n    conn.close()\\n\\ndef insert_war(Krieg_Name, Start_Jahr, End_Jahr):\\n    conn = sqlite3.connect(\"kriege_datenbank.db\")\\n    cursor = conn.cursor()\\n    \\n    cursor.execute(\"\"\"\\n        INSERT INTO kriege (Krieg_Name, Start_Jahr, End_Jahr)\\n        VALUES (?, ?, ?)\\n    \"\"\", (Krieg_Name, Start_Jahr, End_Jahr))\\n    \\n    conn.commit()\\n    conn.close()\\n\\ndef get_all_wars():\\n    conn = sqlite3.connect(\"kriege_datenbank.db\")\\n    cursor = conn.cursor()\\n    \\n    cursor.execute(\"SELECT * FROM kriege\")\\n    wars = cursor.fetchall()\\n    \\n    conn.close()\\n    return wars\\n\\n\\ndef get_all_participants(column_name):\\n    # Connect to the SQLite database\\n    conn = sqlite3.connect(\\'kriege_datenbank.db\\')\\n\\n    # Read a table into a DataFrame\\n    df = pd.read_sql_query(f\"SELECT * FROM KriegeGesamt\", conn)\\n    #print(df.shape)  # Display the first few rows of the DataFrame\\n    #print(df.head()) #DEBUG first 5 rows\\n\\n    # Close the connection when done\\n    conn.close()\\n    return df', 'timestamp': '2025-06-30T19:36:54+0200'}\n",
            "Agent thinking...\n",
            "Agent Decision: {\"tool\": \"read_project_file\", \"args\": {\"name\": \"./SamplePy/wars_barchartrace.py\"}}\n",
            "Action Result: {'tool_executed': True, 'result': \"import bar_chart_race as bcr\\nimport pandas as pd\\n\\n# Example dataframe (wide format, index = time, columns = categories)\\n#df = pd.read_csv('barchartrace_countries_by_year.csv', index_col='Startjahr', parse_dates=True)\\ndf = pd.read_csv('barchartrace_countries_by_opferzahlen.csv', index_col='Startjahr', parse_dates=True)\\n\\nbcr.bar_chart_race(\\n    df=df,\\n    #filename='wars_race.mp4',\\n    filename='wars_death_race.mp4',\\n    orientation='h',\\n    sort='desc',\\n    n_bars=20,\\n    fixed_order=False,\\n    fixed_max=True,\\n    steps_per_period=1,\\n    interpolate_period=True,\\n    period_length=500,\\n    period_label={'x': .95, 'y': .15, 'ha': 'right', 'va': 'center', 'fontsize': 22, 'color': 'black', 'bbox': dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5')},\\n    period_fmt='{x:.0f}',  # Show only the year\\n    title='Vicitims by Wars Participating Countries',\\n    #title='War Count by by Country',\\n    bar_size=.95,\\n    cmap='dark12',\\n    filter_column_colors=True\\n)\", 'timestamp': '2025-06-30T19:36:54+0200'}\n",
            "Agent thinking...\n"
          ]
        },
        {
          "ename": "JSONDecodeError",
          "evalue": "Unterminated string starting at: line 1 column 12 (char 11)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[51], line 102\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Run the agent with user input\u001b[39;00m\n\u001b[1;32m    101\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite a README for all python files in this project.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 102\u001b[0m final_memory \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Extract the README content from the final memory\u001b[39;00m\n\u001b[1;32m    105\u001b[0m memories \u001b[38;5;241m=\u001b[39m final_memory\u001b[38;5;241m.\u001b[39mget_memories()\n",
            "Cell \u001b[0;32mIn[46], line 476\u001b[0m, in \u001b[0;36mAgent.run\u001b[0;34m(self, user_input, memory, max_iterations)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent thinking...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# Generate a response from the agent\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_llm_for_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent Decision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# Determine which action the agent wants to execute\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[46], line 460\u001b[0m, in \u001b[0;36mAgent.prompt_llm_for_action\u001b[0;34m(self, full_prompt)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprompt_llm_for_action\u001b[39m(\u001b[38;5;28mself\u001b[39m, full_prompt: Prompt) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m--> 460\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "Cell \u001b[0;32mIn[46], line 178\u001b[0m, in \u001b[0;36mgenerate_response\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mtool_calls:\n\u001b[1;32m    175\u001b[0m     tool \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mtool_calls[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    176\u001b[0m     result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    179\u001b[0m     }\n\u001b[1;32m    180\u001b[0m     result \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(result)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
            "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
            "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Unterminated string starting at: line 1 column 12 (char 11)"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "folder = None  # Change this to any folder you want to analyze\n",
        "\n",
        "def get_python_files(target_folder=None):\n",
        "    \"\"\"Return a list of all .py files in the given folder or all subfolders if None, excluding .venv and hidden folders.\"\"\"\n",
        "    py_files = []\n",
        "    exclude_dirs = {'.venv', '__pycache__', '.git', '.mypy_cache'}  # Add more if needed\n",
        "\n",
        "    if target_folder and target_folder != \"None\":\n",
        "        for file in os.listdir(target_folder):\n",
        "            if file.endswith(\".py\"):\n",
        "                py_files.append(os.path.join(target_folder, file))\n",
        "    else:\n",
        "        for root, dirs, files in os.walk(\".\"):\n",
        "            # Exclude unwanted directories\n",
        "            dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.startswith('.')]\n",
        "            for file in files:\n",
        "                if file.endswith(\".py\"):\n",
        "                    py_files.append(os.path.join(root, file))\n",
        "    return sorted(py_files)\n",
        "\n",
        "def remove_code_blocks(text):\n",
        "    # Remove triple-backtick code blocks and indented code blocks\n",
        "    text = re.sub(r\"```.*?```\", \"\", text, flags=re.DOTALL)\n",
        "    # Optionally, remove lines that look like code (start with 4 spaces)\n",
        "    text = re.sub(r\"^( {4}.*\\n)+\", \"\", text, flags=re.MULTILINE)\n",
        "    return text.strip()\n",
        "\n",
        "def ask_user_for_folder(): # Function to ask user for a folder to search for Python files\n",
        "    folder = input(\"Enter a folder to search for Python files (leave blank for full project): \").strip()\n",
        "    if folder == \"\":\n",
        "        return None\n",
        "    return folder\n",
        "\n",
        "folder = ask_user_for_folder()\n",
        " \n",
        "# First, we'll define our tools using decorators\n",
        "@register_tool(tags=[\"file_operations\", \"read\"])\n",
        "def read_project_file(name: str) -> str:\n",
        "    \"\"\"Reads and returns the content of a specified project file by full relative path.\n",
        "\n",
        "    Opens the file in read mode and returns its entire contents as a string.\n",
        "    Raises FileNotFoundError if the file doesn't exist.\n",
        "\n",
        "    Args:\n",
        "        name: The name of the file to read\n",
        "\n",
        "    Returns:\n",
        "        The contents of the file as a string\n",
        "    \"\"\"\n",
        "    with open(name, \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "@register_tool(tags=[\"file_operations\", \"list\"])\n",
        "def list_all_python_files(target_folder=folder) -> List[str]:\n",
        "    \"\"\"Lists all Python files in the directory and sub-directory, or all folders if not set.\n",
        "\n",
        "    Scans the directory and returns a sorted list of all files\n",
        "    that end with '.py'.\n",
        "\n",
        "    Returns:\n",
        "        A sorted list of Python filenames\n",
        "    \"\"\"\n",
        "    return get_python_files(target_folder)\n",
        "\n",
        "@register_tool(tags=[\"system\"], terminal=True)\n",
        "def terminate(message: str) -> str:\n",
        "    \"\"\"Terminates the agent's execution with a final message.\n",
        "\n",
        "    Args:\n",
        "        message: The final message to return before terminating\n",
        "\n",
        "    Returns:\n",
        "        The message with a termination note appended\n",
        "    \"\"\"\n",
        "    return f\"{message}\\nTerminating...\"\n",
        "\n",
        "\n",
        "# Define the agent's goals\n",
        "goals = [\n",
        "    Goal(priority=1, \n",
        "            name=\"Gather Information\", \n",
        "            description=f\"For each Python file, summarize its purpose and functionality. Do not include code in the summary.\"),\n",
        "    Goal(priority=1, \n",
        "            name=\"Terminate\", \n",
        "            description=\"Call the terminate call when you have read all the files and provide the content of the README in the terminate message.\")\n",
        "]\n",
        "\n",
        "# Create an agent instance with tag-filtered actions\n",
        "agent = Agent(\n",
        "    goals=goals,\n",
        "    agent_language=AgentFunctionCallingActionLanguage(),\n",
        "    # The ActionRegistry now automatically loads tools with these tags\n",
        "    action_registry=PythonActionRegistry(tags=[\"file_operations\", \"system\"]),\n",
        "    generate_response=generate_response,\n",
        "    environment=Environment()\n",
        ")   \n",
        "\n",
        "# Run the agent with user input\n",
        "user_input = \"Write a README for all python files in this project.\"\n",
        "final_memory = agent.run(user_input)\n",
        "\n",
        "# Extract the README content from the final memory\n",
        "memories = final_memory.get_memories()\n",
        "file_summaries = []\n",
        "\n",
        "# Collect Action Results for read_folder_file (summary/description, not code)\n",
        "for i, mem in enumerate(memories):\n",
        "    if mem[\"type\"] == \"assistant\":\n",
        "        try:\n",
        "            action = json.loads(mem[\"content\"])\n",
        "            if action.get(\"tool\") == \"read_project_file\":  # <-- updated name\n",
        "                file_name = action[\"args\"][\"name\"]\n",
        "                # The next memory should be the environment result\n",
        "                if i + 1 < len(memories):\n",
        "                    env_mem = memories[i + 1]\n",
        "                    if env_mem[\"type\"] == \"environment\":\n",
        "                        env_result = json.loads(env_mem[\"content\"])\n",
        "                        # Only add if tool executed successfully and result is a string\n",
        "                        if env_result.get(\"tool_executed\") and isinstance(env_result.get(\"result\"), str):\n",
        "                            summary = env_result.get(\"result\", \"\")\n",
        "                            summary = remove_code_blocks(summary)\n",
        "                            file_summaries.append(f\"### {os.path.basename(file_name)}\\n**Full path:** `{file_name}`\\n\\n{summary}\\n\")\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "# Find the terminate message for the README summary\n",
        "for mem in reversed(memories):\n",
        "    if mem[\"type\"] == \"environment\":\n",
        "        try:\n",
        "            result = json.loads(mem[\"content\"])\n",
        "            if result.get(\"tool_executed\") and isinstance(result.get(\"result\"), str):\n",
        "                content = result[\"result\"]\n",
        "                if content.strip().endswith(\"Terminating...\"):\n",
        "                    readme_content = content.replace(\"Terminating...\", \"\").strip()\n",
        "                    break\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "# Combine everything into the README\n",
        "full_readme = \"# Project README\\n\\n\"\n",
        "if readme_content:\n",
        "    full_readme += readme_content + \"\\n\\n\"\n",
        "if file_summaries:\n",
        "    full_readme += \"## Python File Summaries\\n\\n\" + \"\\n\".join(file_summaries)\n",
        "\n",
        "# Decide where to save the README\n",
        "if folder:\n",
        "    readme_path = os.path.join(folder, \"README_agent.md\")\n",
        "else:\n",
        "    readme_path = \"README_agent.md\"\n",
        "\n",
        "# Improved error handling for missing folder\n",
        "try:\n",
        "    if folder and not os.path.isdir(folder):\n",
        "        print(f\"Error: The folder '{folder}' does not exist. Please check the folder name and try again.\")\n",
        "    elif full_readme.strip():\n",
        "        with open(readme_path, \"w\") as f:\n",
        "            f.write(full_readme)\n",
        "        print(f\"README_agent.md saved in {os.path.abspath(readme_path)}.\")\n",
        "    else:\n",
        "        print(\"README content not found in memory.\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to write README: {e}\")\n",
        "\n",
        "# Add this before your extraction loop for debugging if needed - it prints all environment memories\n",
        "#for mem in reversed(memories):\n",
        "#print(mem[\"type\"], mem[\"content\"])\n",
        "\n",
        "# Print the final memory\n",
        "print(memories)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
