{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEYrzG2vB8Ip"
      },
      "outputs": [],
      "source": [
        "# Install the required packages using pip in your python environment.\n",
        "#!pip install litellm\n",
        "#!pip install python-dotenv\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()  # Loads variables from .env into environment\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "if not api_key:\n",
        "    raise ValueError(\"OPENAI_API_KEY not found in .env file.\")\n",
        "os.environ['OPENAI_API_KEY'] = api_key     # <---- Reference your OpenAI API key here\n",
        "\n",
        "# There are python files as examples in the /SamplePy directory.\n",
        "# There are sample data files in the /SampleData directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Mwe2eeOQB0cC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "import traceback\n",
        "import inspect\n",
        "from litellm import completion\n",
        "from dataclasses import dataclass, field\n",
        "from typing import get_type_hints, List, Callable, Dict, Any\n",
        "\n",
        "tools = {}\n",
        "tools_by_tag = {}\n",
        "\n",
        "def to_openai_tools(tools_metadata: List[dict]): #function to convert tools metadata to OpenAI function calling format\n",
        "    openai_tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": t['tool_name'],\n",
        "                # Include up to 1024 characters of the description\n",
        "                \"description\": t.get('description',\"\")[:1024],\n",
        "                \"parameters\": t.get('parameters',{}),\n",
        "            },\n",
        "        } for t in tools_metadata\n",
        "    ]\n",
        "    return openai_tools\n",
        "\n",
        "def get_tool_metadata(func, tool_name=None, description=None, parameters_override=None, terminal=False, tags=None): #function to extract metadata for a decorator-function to use in tool registration\n",
        "    \"\"\"\n",
        "    Extracts metadata for a function to use in tool registration.\n",
        "\n",
        "    Parameters:\n",
        "        func (function): The function to extract metadata from.\n",
        "        tool_name (str, optional): The name of the tool. Defaults to the function name.\n",
        "        description (str, optional): Description of the tool. Defaults to the function's docstring.\n",
        "        parameters_override (dict, optional): Override for the argument schema. Defaults to dynamically inferred schema.\n",
        "        terminal (bool, optional): Whether the tool is terminal. Defaults to False.\n",
        "        tags (List[str], optional): List of tags to associate with the tool.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing metadata about the tool, including description, args schema, and the function.\n",
        "    \"\"\"\n",
        "    # Default tool_name to the function name if not provided\n",
        "    tool_name = tool_name or func.__name__\n",
        "\n",
        "    # Default description to the function's docstring if not provided\n",
        "    description = description or (func.__doc__.strip() if func.__doc__ else \"No description provided.\")\n",
        "\n",
        "    # Discover the function's signature and type hints if no args_override is provided\n",
        "    if parameters_override is None:\n",
        "        signature = inspect.signature(func)\n",
        "        type_hints = get_type_hints(func)\n",
        "\n",
        "        # Build the arguments schema dynamically\n",
        "        args_schema = {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {},\n",
        "            \"required\": []\n",
        "        }\n",
        "        for param_name, param in signature.parameters.items():\n",
        "\n",
        "            if param_name in [\"action_context\", \"action_agent\"]:\n",
        "                continue  # Skip these parameters\n",
        "\n",
        "            def get_json_type(param_type):\n",
        "                if param_type == str:\n",
        "                    return \"string\"\n",
        "                elif param_type == int:\n",
        "                    return \"integer\"\n",
        "                elif param_type == float:\n",
        "                    return \"number\"\n",
        "                elif param_type == bool:\n",
        "                    return \"boolean\"\n",
        "                elif param_type == list:\n",
        "                    return \"array\"\n",
        "                elif param_type == dict:\n",
        "                    return \"object\"\n",
        "                else:\n",
        "                    return \"string\"\n",
        "\n",
        "            # Add parameter details\n",
        "            param_type = type_hints.get(param_name, str)  # Default to string if type is not annotated\n",
        "            param_schema = {\"type\": get_json_type(param_type)}  # Convert Python types to JSON schema types\n",
        "\n",
        "            args_schema[\"properties\"][param_name] = param_schema\n",
        "\n",
        "            # Add to required if not defaulted\n",
        "            if param.default == inspect.Parameter.empty:\n",
        "                args_schema[\"required\"].append(param_name)\n",
        "    else:\n",
        "        args_schema = parameters_override\n",
        "\n",
        "    # Return the metadata as a dictionary\n",
        "    return {\n",
        "        \"tool_name\": tool_name,\n",
        "        \"description\": description,\n",
        "        \"parameters\": args_schema,\n",
        "        \"function\": func,\n",
        "        \"terminal\": terminal,\n",
        "        \"tags\": tags or []\n",
        "    }\n",
        "\n",
        "\n",
        "def register_tool(tool_name=None, description=None, parameters_override=None, terminal=False, tags=None):\n",
        "    \"\"\"\n",
        "    A decorator to dynamically register a function in the tools dictionary with its parameters, schema, and docstring.\n",
        "\n",
        "    Parameters:\n",
        "        tool_name (str, optional): The name of the tool to register. Defaults to the function name.\n",
        "        description (str, optional): Override for the tool's description. Defaults to the function's docstring.\n",
        "        parameters_override (dict, optional): Override for the argument schema. Defaults to dynamically inferred schema.\n",
        "        terminal (bool, optional): Whether the tool is terminal. Defaults to False.\n",
        "        tags (List[str], optional): List of tags to associate with the tool.\n",
        "\n",
        "    Returns:\n",
        "        function: The wrapped function.\n",
        "    \"\"\"\n",
        "    def decorator(func):\n",
        "        # Use the reusable function to extract metadata\n",
        "        metadata = get_tool_metadata(\n",
        "            func=func,\n",
        "            tool_name=tool_name,\n",
        "            description=description,\n",
        "            parameters_override=parameters_override,\n",
        "            terminal=terminal,\n",
        "            tags=tags\n",
        "        )\n",
        "\n",
        "        # Register the tool in the global dictionary\n",
        "        tools[metadata[\"tool_name\"]] = {\n",
        "            \"description\": metadata[\"description\"],\n",
        "            \"parameters\": metadata[\"parameters\"],\n",
        "            \"function\": metadata[\"function\"],\n",
        "            \"terminal\": metadata[\"terminal\"],\n",
        "            \"tags\": metadata[\"tags\"] or []\n",
        "        }\n",
        "\n",
        "        for tag in metadata[\"tags\"]:\n",
        "            if tag not in tools_by_tag:\n",
        "                tools_by_tag[tag] = []\n",
        "            tools_by_tag[tag].append(metadata[\"tool_name\"])\n",
        "\n",
        "        return func\n",
        "    return decorator\n",
        "\n",
        "@dataclass # Prompt class to hold messages, tools, and metadata\n",
        "class Prompt:\n",
        "    messages: List[Dict] = field(default_factory=list)\n",
        "    tools: List[Dict] = field(default_factory=list)\n",
        "    metadata: dict = field(default_factory=dict)  # Fixing mutable default issue\n",
        "\n",
        "\n",
        "def generate_response(prompt: Prompt) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "\n",
        "    messages = prompt.messages\n",
        "    tools = prompt.tools\n",
        "\n",
        "    result = None\n",
        "\n",
        "    if not tools:\n",
        "        response = completion(\n",
        "            model=\"openai/gpt-4o\",\n",
        "            messages=messages,\n",
        "            max_tokens=1024\n",
        "        )\n",
        "        result = response.choices[0].message.content\n",
        "    else:\n",
        "        response = completion(\n",
        "            model=\"openai/gpt-4o\",\n",
        "            messages=messages,\n",
        "            tools=tools,\n",
        "            max_tokens=1024\n",
        "        )\n",
        "\n",
        "        if response.choices[0].message.tool_calls:\n",
        "            tool = response.choices[0].message.tool_calls[0]\n",
        "            result = {\n",
        "                \"tool\": tool.function.name,\n",
        "                \"args\": json.loads(tool.function.arguments),\n",
        "            }\n",
        "            result = json.dumps(result)\n",
        "        else:\n",
        "            result = response.choices[0].message.content\n",
        "\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "@dataclass(frozen=True) # Goal class to represent a goal with priority, name, and description\n",
        "class Goal:\n",
        "    priority: int\n",
        "    name: str\n",
        "    description: str\n",
        "\n",
        "\n",
        "class Action: # Action class to represent an action with a name, function, description, parameters, and terminal status\n",
        "    def __init__(self,\n",
        "                 name: str,\n",
        "                 function: Callable,\n",
        "                 description: str,\n",
        "                 parameters: Dict,\n",
        "                 terminal: bool = False):\n",
        "        self.name = name\n",
        "        self.function = function\n",
        "        self.description = description\n",
        "        self.terminal = terminal\n",
        "        self.parameters = parameters\n",
        "\n",
        "    def execute(self, **args) -> Any:\n",
        "        \"\"\"Execute the action's function\"\"\"\n",
        "        return self.function(**args)\n",
        "\n",
        "\n",
        "class ActionRegistry: # ActionRegistry class to hold and manage actions\n",
        "    def __init__(self):\n",
        "        self.actions = {}\n",
        "\n",
        "    def register(self, action: Action):\n",
        "        self.actions[action.name] = action\n",
        "\n",
        "    def get_action(self, name: str) -> [Action, None]:\n",
        "        return self.actions.get(name, None)\n",
        "\n",
        "    def get_actions(self) -> List[Action]:\n",
        "        \"\"\"Get all registered actions\"\"\"\n",
        "        return list(self.actions.values())\n",
        "\n",
        "\n",
        "class Memory: # Memory class to hold conversation history\n",
        "    def __init__(self):\n",
        "        self.items = []  # Basic conversation history\n",
        "\n",
        "    def add_memory(self, memory: dict):\n",
        "        \"\"\"Add memory to working memory\"\"\"\n",
        "        self.items.append(memory)\n",
        "\n",
        "    def get_memories(self, limit: int = None) -> List[Dict]:\n",
        "        \"\"\"Get formatted conversation history for prompt\"\"\"\n",
        "        return self.items[:limit]\n",
        "\n",
        "    def copy_without_system_memories(self):\n",
        "        \"\"\"Return a copy of the memory without system memories\"\"\"\n",
        "        filtered_items = [m for m in self.items if m[\"type\"] != \"system\"]\n",
        "        memory = Memory()\n",
        "        memory.items = filtered_items\n",
        "        return memory\n",
        "\n",
        "\n",
        "class Environment: # Environment class to execute actions and manage results\n",
        "    def execute_action(self, action: Action, args: dict) -> dict: # function to execute an action in the environment\n",
        "        \"\"\"Execute an action and return the result.\"\"\"\n",
        "        try:\n",
        "            result = action.execute(**args)\n",
        "            return self.format_result(result)\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"tool_executed\": False,\n",
        "                \"error\": str(e),\n",
        "                \"traceback\": traceback.format_exc()\n",
        "            }\n",
        "\n",
        "    def format_result(self, result: Any) -> dict: # function to format the result of an action execution\n",
        "        \"\"\"Format the result with metadata.\"\"\"\n",
        "        return {\n",
        "            \"tool_executed\": True,\n",
        "            \"result\": result,\n",
        "            \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
        "        }\n",
        "\n",
        "\n",
        "class AgentLanguage: # Base class for agent languages to define how prompts are constructed and responses are parsed\n",
        "    def __init__(self): # Initialize the agent language\n",
        "        pass\n",
        "\n",
        "    def construct_prompt(self, # Construct a prompt for the agent\n",
        "                         actions: List[Action],\n",
        "                         environment: Environment,\n",
        "                         goals: List[Goal],\n",
        "                         memory: Memory) -> Prompt:\n",
        "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
        "\n",
        "\n",
        "    def parse_response(self, response: str) -> dict: # Parse the response from the agent\n",
        "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
        "\n",
        "\n",
        "\n",
        "class AgentFunctionCallingActionLanguage(AgentLanguage): # AgentLanguage subclass for function calling action language\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def format_goals(self, goals: List[Goal]) -> List:\n",
        "        # Map all goals to a single string that concatenates their description\n",
        "        # and combine into a single message of type system\n",
        "        sep = \"\\n-------------------\\n\"\n",
        "        goal_instructions = \"\\n\\n\".join([f\"{goal.name}:{sep}{goal.description}{sep}\" for goal in goals])\n",
        "        return [\n",
        "            {\"role\": \"system\", \"content\": goal_instructions}\n",
        "        ]\n",
        "\n",
        "    def format_memory(self, memory: Memory) -> List:\n",
        "        \"\"\"Generate response from language model\"\"\"\n",
        "        # Map all environment results to a role:user messages\n",
        "        # Map all assistant messages to a role:assistant messages\n",
        "        # Map all user messages to a role:user messages\n",
        "        items = memory.get_memories()\n",
        "        mapped_items = []\n",
        "        for item in items:\n",
        "\n",
        "            content = item.get(\"content\", None)\n",
        "            if not content:\n",
        "                content = json.dumps(item, indent=4)\n",
        "\n",
        "            if item[\"type\"] == \"assistant\":\n",
        "                mapped_items.append({\"role\": \"assistant\", \"content\": content})\n",
        "            elif item[\"type\"] == \"environment\":\n",
        "                mapped_items.append({\"role\": \"assistant\", \"content\": content})\n",
        "            else:\n",
        "                mapped_items.append({\"role\": \"user\", \"content\": content})\n",
        "\n",
        "        return mapped_items\n",
        "\n",
        "    def format_actions(self, actions: List[Action]) -> [List,List]:\n",
        "        \"\"\"Generate response from language model\"\"\"\n",
        "\n",
        "        tools = [\n",
        "            {\n",
        "                \"type\": \"function\",\n",
        "                \"function\": {\n",
        "                    \"name\": action.name,\n",
        "                    # Include up to 1024 characters of the description\n",
        "                    \"description\": action.description[:1024],\n",
        "                    \"parameters\": action.parameters,\n",
        "                },\n",
        "            } for action in actions\n",
        "        ]\n",
        "\n",
        "        return tools\n",
        "\n",
        "    def construct_prompt(self,  # Construct a prompt for the agent\n",
        "                         actions: List[Action],\n",
        "                         environment: Environment,\n",
        "                         goals: List[Goal],\n",
        "                         memory: Memory) -> Prompt:\n",
        "\n",
        "        prompt = []\n",
        "        prompt += self.format_goals(goals)\n",
        "        prompt += self.format_memory(memory)\n",
        "\n",
        "        tools = self.format_actions(actions)\n",
        "\n",
        "        return Prompt(messages=prompt, tools=tools)\n",
        "\n",
        "    def adapt_prompt_after_parsing_error(self, # Adapt the prompt after a parsing error\n",
        "                                         prompt: Prompt,\n",
        "                                         response: str,\n",
        "                                         traceback: str,\n",
        "                                         error: Any,\n",
        "                                         retries_left: int) -> Prompt:\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def parse_response(self, response: str) -> dict:\n",
        "        \"\"\"Parse LLM response into structured format by extracting the ```json block\"\"\"\n",
        "\n",
        "        try:\n",
        "            return json.loads(response)\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"tool\": \"terminate\",\n",
        "                \"args\": {\"message\":response}\n",
        "            }\n",
        "class PythonActionRegistry(ActionRegistry): # PythonActionRegistry class to hold and manage actions with filtering capabilities\n",
        "    def __init__(self, tags: List[str] = None, tool_names: List[str] = None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.terminate_tool = None\n",
        "\n",
        "        for tool_name, tool_desc in tools.items():\n",
        "            if tool_name == \"terminate\":\n",
        "                self.terminate_tool = tool_desc\n",
        "\n",
        "            if tool_names and tool_name not in tool_names:\n",
        "                continue\n",
        "\n",
        "            tool_tags = tool_desc.get(\"tags\", [])\n",
        "            if tags and not any(tag in tool_tags for tag in tags):\n",
        "                continue\n",
        "\n",
        "            self.register(Action(\n",
        "                name=tool_name,\n",
        "                function=tool_desc[\"function\"],\n",
        "                description=tool_desc[\"description\"],\n",
        "                parameters=tool_desc.get(\"parameters\", {}),\n",
        "                terminal=tool_desc.get(\"terminal\", False)\n",
        "            ))\n",
        "\n",
        "    def register_terminate_tool(self):\n",
        "        if self.terminate_tool:\n",
        "            self.register(Action(\n",
        "                name=\"terminate\",\n",
        "                function=self.terminate_tool[\"function\"],\n",
        "                description=self.terminate_tool[\"description\"],\n",
        "                parameters=self.terminate_tool.get(\"parameters\", {}),\n",
        "                terminal=self.terminate_tool.get(\"terminal\", False)\n",
        "            ))\n",
        "        else:\n",
        "            raise Exception(\"Terminate tool not found in tool registry\")\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self,\n",
        "                 goals: List[Goal],\n",
        "                 agent_language: AgentLanguage,\n",
        "                 action_registry: ActionRegistry,\n",
        "                 generate_response: Callable[[Prompt], str],\n",
        "                 environment: Environment):\n",
        "        \"\"\"\n",
        "        Initialize an agent with its core GAME components\n",
        "        \"\"\"\n",
        "        self.goals = goals\n",
        "        self.generate_response = generate_response\n",
        "        self.agent_language = agent_language\n",
        "        self.actions = action_registry\n",
        "        self.environment = environment\n",
        "\n",
        "    def construct_prompt(self, goals: List[Goal], memory: Memory, actions: ActionRegistry) -> Prompt:\n",
        "        \"\"\"Build prompt with memory context\"\"\"\n",
        "        return self.agent_language.construct_prompt(\n",
        "            actions=actions.get_actions(),\n",
        "            environment=self.environment,\n",
        "            goals=goals,\n",
        "            memory=memory\n",
        "        )\n",
        "\n",
        "    def get_action(self, response):\n",
        "        invocation = self.agent_language.parse_response(response)\n",
        "        action = self.actions.get_action(invocation[\"tool\"])\n",
        "        return action, invocation\n",
        "\n",
        "    def should_terminate(self, response: str) -> bool:\n",
        "        action_def, _ = self.get_action(response)\n",
        "        return action_def.terminal\n",
        "\n",
        "    def set_current_task(self, memory: Memory, task: str):\n",
        "        memory.add_memory({\"type\": \"user\", \"content\": task})\n",
        "\n",
        "    def update_memory(self, memory: Memory, response: str, result: dict):\n",
        "        \"\"\"\n",
        "        Update memory with the agent's decision and the environment's response.\n",
        "        \"\"\"\n",
        "        new_memories = [\n",
        "            {\"type\": \"assistant\", \"content\": response},\n",
        "            {\"type\": \"environment\", \"content\": json.dumps(result)}\n",
        "        ]\n",
        "        for m in new_memories:\n",
        "            memory.add_memory(m)\n",
        "\n",
        "    def prompt_llm_for_action(self, full_prompt: Prompt) -> str:\n",
        "        response = self.generate_response(full_prompt)\n",
        "        return response\n",
        "\n",
        "    def run(self, user_input: str, memory=None, max_iterations: int = 50) -> Memory:\n",
        "        \"\"\"\n",
        "        Execute the GAME loop for this agent with a maximum iteration limit.\n",
        "        \"\"\"\n",
        "        memory = memory or Memory()\n",
        "        self.set_current_task(memory, user_input)\n",
        "\n",
        "        for _ in range(max_iterations):\n",
        "            # Construct a prompt that includes the Goals, Actions, and the current Memory\n",
        "            prompt = self.construct_prompt(self.goals, memory, self.actions)\n",
        "\n",
        "            print(\"Agent thinking...\")\n",
        "            # Generate a response from the agent\n",
        "            response = self.prompt_llm_for_action(prompt)\n",
        "            print(f\"Agent Decision: {response}\")\n",
        "\n",
        "            # Determine which action the agent wants to execute\n",
        "            action, invocation = self.get_action(response)\n",
        "\n",
        "            # Execute the action in the environment\n",
        "            result = self.environment.execute_action(action, invocation[\"args\"])\n",
        "            print(f\"Action Result: {result}\")\n",
        "\n",
        "            # Update the agent's memory with information about what happened\n",
        "            self.update_memory(memory, response, result)\n",
        "\n",
        "            # Check if the agent has decided to terminate\n",
        "            if self.should_terminate(response):\n",
        "                break\n",
        "\n",
        "        return memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PC3ncxezoJC",
        "outputId": "564b75ed-bcc3-4f59-c51f-ed4e39d7bf90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent thinking...\n",
            "Agent Decision: {\"tool\": \"list_folder_files\", \"args\": {}}\n",
            "Action Result: {'tool_executed': True, 'result': ['SamplePy/NormalizeCountries.py', 'SamplePy/analyze_import2.py', 'SamplePy/database_operations.py', 'SamplePy/wars_barchartrace.py'], 'timestamp': '2025-06-30T18:16:18+0200'}\n",
            "Agent thinking...\n",
            "Agent Decision: {\"tool\": \"read_folder_file\", \"args\": {\"name\": \"SamplePy/NormalizeCountries.py\"}}\n",
            "Action Result: {'tool_executed': True, 'result': 'import re\\nfrom database_operations import get_all_participants # Import database functions\\nfrom mapping import kriegsteilnehmer_mapping_red #import mapping table from a separate module\\nimport pandas as pd\\nimport numpy as np\\n\\n\\ndef process_country_list(country_list_string, mapping_table):\\n    \"\"\"\\n    Processes a single string containing a list of countries and maps them\\n    to the keys in the provided mapping table.\\n\\n    Args:\\n        country_list_string (str): The string from your database column (e.g., \"Alliierte (USA,Großbritannien,Kanada,Freie Französische Streitkräfte,Polen u.a.)\").\\n        mapping_table (dict): The mapping table (kriegsteilnehmer_mapping_red).\\n\\n    Returns:\\n        list: A list of mapped \"canonical\" country names (keys from the mapping table)\\n              found in the input string.\\n    \"\"\"\\n    mapped_countries = set()\\n\\n    # 1. Extract individual country names from the string\\n    # This regex tries to capture names that are separated by commas,\\n    # or inside parentheses. It\\'s a bit robust.\\n    # It also handles \"u.a.\" by ignoring it.\\n    extracted_countries = re.findall(r\\'[\\\\w\\\\säöüÄÖÜß\\\\.-]+\\', country_list_string)\\n    # Filter out common separators or indicators that aren\\'t country names\\n    extracted_countries = [\\n        country.strip() for country in extracted_countries\\n        if country.strip() and country.strip().lower() not in [\"u.a.\", \"\"]\\n    ]\\n    # Further refinement for parenthetical content\\n    if \\'(\\' in country_list_string and \\')\\' in country_list_string:\\n        parenthetical_content = re.search(r\\'\\\\((.*?)\\\\)\\', country_list_string)\\n        if parenthetical_content:\\n            inner_countries = [c.strip() for c in parenthetical_content.group(1).split(\\',\\')]\\n            extracted_countries.extend(inner_countries)\\n    # Remove duplicates and refine the list\\n    extracted_countries = list(set([re.sub(r\\'\\\\s*\\\\(.*\\\\)\\\\s*\\', \\'\\', c).strip() for c in extracted_countries]))\\n    extracted_countries = [c for c in extracted_countries if c] # Remove empty strings\\n\\n\\n    # 2. Iterate through your mapping table to find matches\\n    for canonical_name, aliases_str in mapping_table.items():\\n        aliases = [alias.strip() for alias in aliases_str.split(\\',\\')]\\n        for extracted in extracted_countries:\\n            if extracted in aliases:\\n                mapped_countries.add(canonical_name)\\n                break # Once a match is found for this canonical name, move to the next one\\n\\n    return list(mapped_countries)\\n\\n# Example usage with your provided database strings:\\n#print(\"Before shape\")\\ndb_aggressors = get_all_participants(\\'Parteien_Seite_Aggressor\\')  # Assuming this function returns a list of strings from your database\\ndb_defenders = get_all_participants(\\'Parteien_Seite_Verteidiger\\')  # Assuming this function returns a list of strings from your database\\n#print(db_strings.head())  # Display the first few rows of the DataFrame\\n#print(\"After shape\")\\n#print(df.head()) #DEBUG first 5 rows\\n\\n# Start with the original DataFrame (e.g. db_aggressors)\\ndf = db_aggressors.copy()\\n\\n# Map aggressors\\ndf[\\'mapped_Parteien_Seite_Aggressor\\'] = df[\\'Parteien_Seite_Aggressor\\'].apply(lambda x: process_country_list(x, kriegsteilnehmer_mapping_red))\\nfor idx, mapped_list in df[\\'mapped_Parteien_Seite_Aggressor\\'].items():\\n    for country in mapped_list:\\n        df.at[idx, country] = \\'Agressor\\'\\n\\n# Map defenders (use the same DataFrame!)\\ndf[\\'mapped_Parteien_Seite_Verteidiger\\'] = db_defenders[\\'Parteien_Seite_Verteidiger\\'].apply(lambda x: process_country_list(x, kriegsteilnehmer_mapping_red))\\nfor idx, mapped_list in df[\\'mapped_Parteien_Seite_Verteidiger\\'].items():\\n    for country in mapped_list:\\n        # Create the column if it does not exist\\n        if country not in df.columns:\\n            df[country] = np.nan\\n        # If already \\'Agressor\\', set to \\'Both\\', else \\'Defender\\'\\n        if df.at[idx, country] == \\'Agressor\\':\\n            df.at[idx, country] = \\'Both\\'\\n        else:\\n            df.at[idx, country] = \\'Defender\\'\\n\\n# Optional: fill NaN with False for all new columns (canonical country names)\\n#country_columns = set([country for sublist in df[\\'mapped_Parteien_Seite_Aggressor\\'] for country in sublist])\\n#df[list(country_columns)] = df[list(country_columns)].fillna(False)\\n\\n# Save the DataFrame to a CSV file\\n#df.to_csv(\"normalized_participants.csv\", index=False)\\n\\n# Open a connection to your existing database\\n# Convert lists to comma-separated strings for database storage\\ndf[\\'mapped_Parteien_Seite_Aggressor\\'] = df[\\'mapped_Parteien_Seite_Aggressor\\'].apply(lambda x: \\', \\'.join(x) if isinstance(x, list) else str(x))\\ndf[\\'mapped_Parteien_Seite_Verteidiger\\'] = df[\\'mapped_Parteien_Seite_Verteidiger\\'].apply(lambda x: \\', \\'.join(x) if isinstance(x, list) else str(x))\\nimport sqlite3\\nconn = sqlite3.connect(\\'kriege_datenbank.db\\')\\n# Write the DataFrame to a new table, e.g. \"normalized_participants\"\\ndf.to_sql(\\'KriegeGlobalTeilnehmer\\', conn, if_exists=\\'replace\\', index=False)\\nconn.close()\\n\\n\\n\\n\\n\\n# After both loops for aggressor and defender, collect all country columns\\n# (they are the columns that are not in the original db_defenders columns or mapped columns)\\noriginal_columns = set(db_defenders.columns) | {\\'mapped_Parteien_Seite_Aggressor\\', \\'mapped_Parteien_Seite_Verteidiger\\'}\\ncountry_columns = [col for col in df.columns if col not in original_columns]\\n\\nfrom itertools import permutations\\n\\nmax_count = 0\\nmax_pair = (None, None)\\n\\nfor country1, country2 in permutations(country_columns, 2):\\n    # country1 ist Aggressor, country2 ist Defender in derselben Zeile\\n    count = ((df[country1] == \\'Agressor\\') & (df[country2] == \\'Defender\\')).sum()\\n    if count > max_count:\\n        max_count = count\\n        max_pair = (country1, country2)\\n\\nprint(f\"The pair of countries most often on different sides (Aggressor/Defender): {max_pair} ({max_count} rows)\")\\n\\n# Zähle für jedes Land, wie oft es \"Agressor\" oder \"Defender\" ist\\naggressor_counts = {}\\ndefender_counts = {}\\n\\nfor country in country_columns:\\n    aggressor_counts[country] = (df[country] == \\'Agressor\\').sum()\\n    defender_counts[country] = (df[country] == \\'Defender\\').sum()\\n\\n# Finde das Land mit den meisten \"Agressor\"- und \"Defender\"-Einträgen\\nmost_aggressor = max(aggressor_counts, key=aggressor_counts.get)\\nmost_defender = max(defender_counts, key=defender_counts.get)\\n\\nprint(f\"Most frequent Aggressor: {most_aggressor} ({aggressor_counts[most_aggressor]} times)\")\\nprint(f\"Most frequent Defender: {most_defender} ({defender_counts[most_defender]} times)\")\\n\\nboth_counts = {}\\n\\nfor country in country_columns:\\n    both_counts[country] = aggressor_counts[country] + defender_counts[country]\\n\\nmost_both = max(both_counts, key=both_counts.get)\\nprint(f\"Country most often involved as both Aggressor and Defender: {most_both} ({both_counts[most_both]} times)\")\\n\\n\\nboth_role_counts = {}\\n\\nfor country in country_columns:\\n    both_role_counts[country] = (df[country] == \\'Both\\').sum()\\n\\n# Sort and print the results\\nfor country, count in sorted(both_role_counts.items(), key=lambda x: x[1], reverse=True):\\n    if count > 0:\\n        print(f\"{country}: {count} times as Both\")\\n\\n\\n# Bar_chart_race Kriegsteilnahmen\\n# 1. Wähle die relevanten Spalten aus\\n# Annahme: \\'Startjahr\\' ist numerisch, country_columns enthält alle Länder-Spalten\\ndf_bcr = df[[\\'Startjahr\\'] + country_columns].copy()\\n\\n# 2. Ersetze alle Nicht-NaN-Werte durch 1 (Beteiligung), sonst 0\\nfor country in country_columns:\\n    df_bcr[country] = df_bcr[country].notna().astype(int)\\n\\n# 3. Gruppiere nach Jahr und summiere die Beteiligungen\\ndf_bcr_grouped = df_bcr.groupby(\\'Startjahr\\')[country_columns].sum()\\ndf_bcr_cumulative = df_bcr_grouped.cumsum()\\n\\n# Optional: Sortiere die Jahre aufsteigend\\ndf_bcr_cumulative = df_bcr_cumulative.sort_index()\\n\\n# 4. Speichere das Ergebnis für bar_chart_race\\ndf_bcr_cumulative.to_csv(\"barchartrace_countries_by_year.csv\")\\n\\n#print(df_bcr_grouped.head())\\n\\n\\n\\n# Bar_chart_race Kriegsopferzahlen\\n# 1. Prepare a DataFrame with Startjahr, Opferzahlen_Gesamt_bis, and country columns\\ndf_opfer = df[[\\'Startjahr\\', \\'Opferzahlen_Gesamt_bis\\'] + country_columns].copy()\\n\\n# 2. For each country, set value to Opferzahlen_Gesamt_bis if participating, else 0\\nfor country in country_columns:\\n    df_opfer[country] = df_opfer[country].notna().astype(int) * df_opfer[\\'Opferzahlen_Gesamt_bis\\'].fillna(0)\\n\\n# 3. Group by year and sum\\ndf_opfer_grouped = df_opfer.groupby(\\'Startjahr\\')[country_columns].sum()\\n\\n# 4. Cumulative sum over years\\ndf_opfer_cumulative = df_opfer_grouped.cumsum().sort_index()\\n\\n# 5. Save for bar_chart_race\\ndf_opfer_cumulative.to_csv(\"barchartrace_countries_by_opferzahlen.csv\")\\n#print(df_opfer_cumulative.head())', 'timestamp': '2025-06-30T18:16:20+0200'}\n",
            "Agent thinking...\n",
            "Agent Decision: {\"tool\": \"read_folder_file\", \"args\": {\"name\": \"SamplePy/analyze_import2.py\"}}\n",
            "Action Result: {'tool_executed': True, 'result': 'import csv\\nimport sqlite3\\nfrom collections import Counter # Um Duplikate leicht zu zählen\\n\\n# --- Konfiguration ---\\nCSV_FILE_PATH = \\'China.csv\\'\\nDB_FILE_PATH = \\'kriege_datenbank.db\\'\\nTABLE_NAME = \\'KriegeChina\\'\\nCSV_KRIEG_COLUMN_INDEX = 0\\nDB_KRIEG_COLUMN_NAME = \\'Krieg\\'\\nEXPECTED_COLUMNS_IN_DATA = 14 # Die Anzahl der Spalten in deinen Datenzeilen\\n\\ndef compare_csv_and_db_wars():\\n    csv_war_list_all = [] # Liste aller Kriegsnamen aus der CSV\\n    csv_skipped_rows = 0\\n\\n    print(f\"Lese Kriege aus CSV-Datei: {CSV_FILE_PATH}\")\\n    try:\\n        with open(CSV_FILE_PATH, mode=\\'r\\', encoding=\\'utf-8-sig\\') as csvfile:\\n            csv_reader = csv.reader(csvfile)\\n            header = next(csv_reader)\\n\\n            for i, row in enumerate(csv_reader):\\n                current_row_num_in_file = i + 2\\n                if not any(field.strip() for field in row):\\n                    csv_skipped_rows +=1\\n                    continue\\n                if len(row) != EXPECTED_COLUMNS_IN_DATA:\\n                    print(f\"Info CSV: Zeile {current_row_num_in_file} hat {len(row)} Spalten, erwartet {EXPECTED_COLUMNS_IN_DATA}. Übersprungen für diesen Vergleich.\")\\n                    csv_skipped_rows +=1\\n                    continue\\n                try:\\n                    war_name = row[CSV_KRIEG_COLUMN_INDEX].strip()\\n                    if war_name: # Nur hinzufügen, wenn der Name nicht leer ist\\n                        csv_war_list_all.append(war_name)\\n                    else:\\n                        print(f\"Info CSV: Kriegsname in Zeile {current_row_num_in_file} ist leer.\")\\n                        csv_skipped_rows +=1\\n                except IndexError:\\n                    print(f\"Fehler CSV: Zeile {current_row_num_in_file} hat nicht genügend Spalten für Kriegsnamen.\")\\n                    csv_skipped_rows +=1\\n                    continue\\n    except FileNotFoundError:\\n        print(f\"Fehler: CSV-Datei \\'{CSV_FILE_PATH}\\' nicht gefunden.\")\\n        return\\n    except Exception as e:\\n        print(f\"Fehler beim Lesen der CSV: {e}\")\\n        return\\n\\n    print(f\"{len(csv_war_list_all)} Kriege (potenziell mit Duplikaten) aus CSV geladen (nach Überspringen von {csv_skipped_rows} Zeilen).\")\\n\\n    # Zähle Duplikate in der CSV\\n    csv_war_counts = Counter(csv_war_list_all)\\n    csv_unique_wars_set = set(csv_war_list_all)\\n    csv_duplicate_names = {name: count for name, count in csv_war_counts.items() if count > 1}\\n\\n    print(f\"{len(csv_unique_wars_set)} einzigartige Kriegsnamen in der CSV-Liste.\")\\n    if csv_duplicate_names:\\n        print(f\"{len(csv_duplicate_names)} Kriegsname(n) kommen in der CSV mehrfach vor:\")\\n        for name, count in csv_duplicate_names.items():\\n            print(f\"  - \\'{name}\\' (kommt {count} Mal vor)\")\\n    else:\\n        print(\"Keine Duplikate (basierend auf Kriegsnamen) in der CSV-Liste gefunden.\")\\n\\n    # --- Aus der Datenbank lesen ---\\n    db_war_list_all = []\\n    db_row_count_actual = 0\\n    conn_db_count = None\\n    try:\\n        conn_db_count = sqlite3.connect(DB_FILE_PATH)\\n        cursor_db_count = conn_db_count.cursor()\\n        # Tatsächliche Zeilenzahl ermitteln\\n        cursor_db_count.execute(f\"SELECT COUNT(*) FROM {TABLE_NAME}\")\\n        db_row_count_actual = cursor_db_count.fetchone()[0]\\n\\n        # Alle Kriegsnamen aus der DB holen\\n        cursor_db_count.execute(f\"SELECT \\\\\"{DB_KRIEG_COLUMN_NAME}\\\\\" FROM {TABLE_NAME}\")\\n        for row in cursor_db_count:\\n            if row[0] is not None: # Ignoriere NULL-Werte für den Kriegsnamen, falls vorhanden\\n                 db_war_list_all.append(row[0].strip())\\n            else:\\n                print(\"Info DB: Ein Kriegsname in der DB ist NULL.\")\\n        conn_db_count.close()\\n    except sqlite3.Error as e:\\n        print(f\"SQLite Fehler beim Lesen der DB: {e}\")\\n        if conn_db_count: conn_db_count.close()\\n        return\\n\\n    print(f\"\\\\nDatenbank-Analyse:\")\\n    print(f\"Tatsächliche Zeilenanzahl in DB-Tabelle \\'{TABLE_NAME}\\' laut COUNT(*): {db_row_count_actual}\")\\n    print(f\"{len(db_war_list_all)} Kriegsnamen aus DB geladen (nach .strip() und ohne NULLs).\")\\n\\n    db_war_counts = Counter(db_war_list_all)\\n    db_unique_wars_set = set(db_war_list_all)\\n    db_duplicate_names = {name: count for name, count in db_war_counts.items() if count > 1}\\n\\n    print(f\"{len(db_unique_wars_set)} einzigartige Kriegsnamen in der DB-Liste (nach .strip()).\")\\n    if db_duplicate_names:\\n        print(f\"ACHTUNG: {len(db_duplicate_names)} Kriegsname(n) kommen in der DB-Liste MEHRFACH vor (sollte bei PRIMARY KEY nicht sein, es sei denn .strip() führt zu Kollisionen):\")\\n        for name, count in db_duplicate_names.items():\\n            print(f\"  - \\'{name}\\' (kommt {count} Mal vor in der DB-Liste nach .strip())\")\\n    else:\\n        print(\"Keine Duplikate in der DB-Liste der Kriegsnamen gefunden (nach .strip()).\")\\n\\n\\n    # --- Vergleiche die Sets ---\\n    print(\"\\\\nVergleich der einzigartigen Kriegsnamen-Sets:\")\\n    missing_in_db_set = csv_unique_wars_set - db_unique_wars_set\\n    missing_in_csv_set = db_unique_wars_set - csv_unique_wars_set\\n\\n    if missing_in_db_set:\\n        print(f\"\\\\n{len(missing_in_db_set)} EINZIGARTIGE Kriege sind im CSV-Set, aber NICHT im DB-Set:\")\\n        for war in sorted(list(missing_in_db_set)):\\n            print(f\"  - \\'{war}\\'\")\\n    else:\\n        print(\"\\\\nAlle einzigartigen Kriege aus dem CSV-Set sind auch im DB-Set vorhanden.\")\\n\\n    if missing_in_csv_set:\\n        print(f\"\\\\n{len(missing_in_csv_set)} EINZIGARTIGE Kriege sind im DB-Set, aber NICHT im CSV-Set (sollte nicht passieren, wenn CSV die Quelle ist):\")\\n        for war in sorted(list(missing_in_csv_set)):\\n            print(f\"  - \\'{war}\\'\")\\n    else:\\n        print(\"\\\\nAlle einzigartigen Kriege aus dem DB-Set sind auch im CSV-Set vorhanden.\")\\n\\n    print(\"\\\\n--- Zusammenfassung der Zählungen ---\")\\n    print(f\"CSV: {len(csv_war_list_all)} gelesene Namen (potenziell mit Duplikaten)\")\\n    print(f\"CSV: {len(csv_unique_wars_set)} einzigartige Namen\")\\n    print(f\"DB (COUNT(*)): {db_row_count_actual} Zeilen\")\\n    print(f\"DB: {len(db_war_list_all)} gelesene Namen (ignoriert NULLs, .strip() angewendet)\")\\n    print(f\"DB: {len(db_unique_wars_set)} einzigartige Namen (nach .strip())\")\\n\\n    if len(csv_unique_wars_set) == db_row_count_actual and not missing_in_db_set and not missing_in_csv_set and not csv_duplicate_names:\\n        print(\"\\\\nPerfekte Übereinstimmung zwischen einzigartigen CSV-Namen und DB-Zeilenanzahl, keine Duplikate in CSV.\")\\n    elif len(csv_war_list_all) - len(csv_duplicate_names) == db_row_count_actual and not missing_in_db_set and not missing_in_csv_set :\\n         # Diese Logik ist nicht ganz korrekt, wenn csv_duplicate_names die Anzahl der Namen ist, nicht die Anzahl der Duplikat-Instanzen\\n         num_lost_to_duplicates = sum(count - 1 for count in csv_duplicate_names.values())\\n         if len(csv_war_list_all) - num_lost_to_duplicates == db_row_count_actual:\\n            print(f\"\\\\nDie Differenz zwischen CSV-Rohdaten ({len(csv_war_list_all)}) und DB-Zeilen ({db_row_count_actual}) scheint durch {num_lost_to_duplicates} Duplikat-Instanzen in der CSV erklärt zu werden.\")\\n\\n\\nif __name__ == \\'__main__\\':\\n    compare_csv_and_db_wars()', 'timestamp': '2025-06-30T18:16:22+0200'}\n",
            "Agent thinking...\n",
            "Agent Decision: {\"tool\": \"read_folder_file\", \"args\": {\"name\": \"SamplePy/database_operations.py\"}}\n",
            "Action Result: {'tool_executed': True, 'result': 'import sqlite3\\nimport pandas as pd\\n\\ndef reset_database(table):\\n    conn = sqlite3.connect(\"kriege_datenbank.db\")\\n    cursor = conn.cursor()\\n    \\n    # Lösche die Tabelle, falls sie existiert\\n    cursor.execute(\"DROP TABLE IF EXISTS table\")\\n    \\n    # Erstelle die Tabelle neu\\n    cursor.execute(\"\"\"\\n        CREATE TABLE table (\\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\\n            Krieg_Name TEXT NOT NULL,\\n            Start_Jahr INTEGER,\\n            End_Jahr INTEGER\\n        )\\n    \"\"\")\\n    \\n    conn.commit()\\n    conn.close()\\n\\ndef delete_duplicates_from_wars():\\n    conn = sqlite3.connect(\"kriege_datenbank.db\")\\n    cursor = conn.cursor()\\n\\n    # Lösche Duplikate basierend auf name, Start_Jahr und End_Jahr\\n    cursor.execute(\"\"\"\\n        DELETE FROM kriege\\n        WHERE rowid NOT IN (\\n            SELECT MIN(rowid)\\n            FROM kriege\\n            GROUP BY Krieg_Name, Start_Jahr, End_Jahr\\n        )\\n    \"\"\")\\n    conn.commit()\\n    conn.close()\\n\\ndef insert_war(Krieg_Name, Start_Jahr, End_Jahr):\\n    conn = sqlite3.connect(\"kriege_datenbank.db\")\\n    cursor = conn.cursor()\\n    \\n    cursor.execute(\"\"\"\\n        INSERT INTO kriege (Krieg_Name, Start_Jahr, End_Jahr)\\n        VALUES (?, ?, ?)\\n    \"\"\", (Krieg_Name, Start_Jahr, End_Jahr))\\n    \\n    conn.commit()\\n    conn.close()\\n\\ndef get_all_wars():\\n    conn = sqlite3.connect(\"kriege_datenbank.db\")\\n    cursor = conn.cursor()\\n    \\n    cursor.execute(\"SELECT * FROM kriege\")\\n    wars = cursor.fetchall()\\n    \\n    conn.close()\\n    return wars\\n\\n\\ndef get_all_participants(column_name):\\n    # Connect to the SQLite database\\n    conn = sqlite3.connect(\\'kriege_datenbank.db\\')\\n\\n    # Read a table into a DataFrame\\n    df = pd.read_sql_query(f\"SELECT * FROM KriegeGesamt\", conn)\\n    #print(df.shape)  # Display the first few rows of the DataFrame\\n    #print(df.head()) #DEBUG first 5 rows\\n\\n    # Close the connection when done\\n    conn.close()\\n    return df', 'timestamp': '2025-06-30T18:16:23+0200'}\n",
            "Agent thinking...\n",
            "Agent Decision: {\"tool\": \"read_folder_file\", \"args\": {\"name\": \"SamplePy/wars_barchartrace.py\"}}\n",
            "Action Result: {'tool_executed': True, 'result': \"import bar_chart_race as bcr\\nimport pandas as pd\\n\\n# Example dataframe (wide format, index = time, columns = categories)\\n#df = pd.read_csv('barchartrace_countries_by_year.csv', index_col='Startjahr', parse_dates=True)\\ndf = pd.read_csv('barchartrace_countries_by_opferzahlen.csv', index_col='Startjahr', parse_dates=True)\\n\\nbcr.bar_chart_race(\\n    df=df,\\n    #filename='wars_race.mp4',\\n    filename='wars_death_race.mp4',\\n    orientation='h',\\n    sort='desc',\\n    n_bars=20,\\n    fixed_order=False,\\n    fixed_max=True,\\n    steps_per_period=1,\\n    interpolate_period=True,\\n    period_length=500,\\n    period_label={'x': .95, 'y': .15, 'ha': 'right', 'va': 'center', 'fontsize': 22, 'color': 'black', 'bbox': dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5')},\\n    period_fmt='{x:.0f}',  # Show only the year\\n    title='Vicitims by Wars Participating Countries',\\n    #title='War Count by by Country',\\n    bar_size=.95,\\n    cmap='dark12',\\n    filter_column_colors=True\\n)\", 'timestamp': '2025-06-30T18:16:24+0200'}\n",
            "Agent thinking...\n",
            "Agent Decision: {\"tool\": \"terminate\", \"args\": {\"message\": \"This project is set up to analyze historical wars using data from a CSV and a database. Below is an overview of the functionality provided by each script:\\n\\n### Files and Their Descriptions:\\n\\n1. **NormalizeCountries.py**:\\n   - This script processes country names from a database field and maps them to standardized names using a mapping table.\\n   - It performs data transformation including cleaning country lists, mapping them to canonical names, and updating a database based on these mappings.\\n   - The script outputs processed data to both CSV files and a SQLite database.\\n\\n2. **analyze_import2.py**:\\n   - It compares war names between a CSV file and a SQLite database to identify duplicates and mismatches.\\n   - Outputs the analysis of unique and duplicate war names from both sources to help verify data integrity and consistency.\\n\\n3. **database_operations.py**:\\n   - Contains functions for interacting with the SQLite database, such as resetting tables, deleting duplicates, inserting new records, and retrieving data.\\n   - Simplifies repetitive database tasks to streamline data handling processes.\\n\\n4. **wars_barchartrace.py**:\\n   - Uses the bar_chart_race library to create visual bar chart race animations representing war-related statistics over time.\\n   - The script reads preprocessed data and generates animations showcasing the evolution of countries' involvement or victim counts in wars.\\n\\n### Additional Context:\\n- **Data Flows**: Data is pulled from a CSV and manipulated to ensure consistency before being saved into the database. Each module has a specific role ranging from data normalization, verification, and visual representation.\\n- **Database**: SQLite is used for storing and querying war data. This helps in managing persistent state and allowing complex queries to be run on the dataset.\\n- **Visualization**: The visualizations generated help in understanding trends and patterns in war data over time, pointed by either the count of wars or the human impact through victim counts.\\n\\nThis project combines data engineering, transformation, and visualization to offer insights into historical wars and their participants effectively.\"}}\n",
            "Action Result: {'tool_executed': True, 'result': \"This project is set up to analyze historical wars using data from a CSV and a database. Below is an overview of the functionality provided by each script:\\n\\n### Files and Their Descriptions:\\n\\n1. **NormalizeCountries.py**:\\n   - This script processes country names from a database field and maps them to standardized names using a mapping table.\\n   - It performs data transformation including cleaning country lists, mapping them to canonical names, and updating a database based on these mappings.\\n   - The script outputs processed data to both CSV files and a SQLite database.\\n\\n2. **analyze_import2.py**:\\n   - It compares war names between a CSV file and a SQLite database to identify duplicates and mismatches.\\n   - Outputs the analysis of unique and duplicate war names from both sources to help verify data integrity and consistency.\\n\\n3. **database_operations.py**:\\n   - Contains functions for interacting with the SQLite database, such as resetting tables, deleting duplicates, inserting new records, and retrieving data.\\n   - Simplifies repetitive database tasks to streamline data handling processes.\\n\\n4. **wars_barchartrace.py**:\\n   - Uses the bar_chart_race library to create visual bar chart race animations representing war-related statistics over time.\\n   - The script reads preprocessed data and generates animations showcasing the evolution of countries' involvement or victim counts in wars.\\n\\n### Additional Context:\\n- **Data Flows**: Data is pulled from a CSV and manipulated to ensure consistency before being saved into the database. Each module has a specific role ranging from data normalization, verification, and visual representation.\\n- **Database**: SQLite is used for storing and querying war data. This helps in managing persistent state and allowing complex queries to be run on the dataset.\\n- **Visualization**: The visualizations generated help in understanding trends and patterns in war data over time, pointed by either the count of wars or the human impact through victim counts.\\n\\nThis project combines data engineering, transformation, and visualization to offer insights into historical wars and their participants effectively.\\nTerminating...\", 'timestamp': '2025-06-30T18:16:36+0200'}\n",
            "README.md saved in SamplePy.\n",
            "[{'type': 'user', 'content': 'Write a README for this project.'}, {'type': 'assistant', 'content': '{\"tool\": \"list_folder_files\", \"args\": {}}'}, {'type': 'environment', 'content': '{\"tool_executed\": true, \"result\": [\"SamplePy/NormalizeCountries.py\", \"SamplePy/analyze_import2.py\", \"SamplePy/database_operations.py\", \"SamplePy/wars_barchartrace.py\"], \"timestamp\": \"2025-06-30T18:16:18+0200\"}'}, {'type': 'assistant', 'content': '{\"tool\": \"read_folder_file\", \"args\": {\"name\": \"SamplePy/NormalizeCountries.py\"}}'}, {'type': 'environment', 'content': '{\"tool_executed\": true, \"result\": \"import re\\\\nfrom database_operations import get_all_participants # Import database functions\\\\nfrom mapping import kriegsteilnehmer_mapping_red #import mapping table from a separate module\\\\nimport pandas as pd\\\\nimport numpy as np\\\\n\\\\n\\\\ndef process_country_list(country_list_string, mapping_table):\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    Processes a single string containing a list of countries and maps them\\\\n    to the keys in the provided mapping table.\\\\n\\\\n    Args:\\\\n        country_list_string (str): The string from your database column (e.g., \\\\\"Alliierte (USA,Gro\\\\u00dfbritannien,Kanada,Freie Franz\\\\u00f6sische Streitkr\\\\u00e4fte,Polen u.a.)\\\\\").\\\\n        mapping_table (dict): The mapping table (kriegsteilnehmer_mapping_red).\\\\n\\\\n    Returns:\\\\n        list: A list of mapped \\\\\"canonical\\\\\" country names (keys from the mapping table)\\\\n              found in the input string.\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    mapped_countries = set()\\\\n\\\\n    # 1. Extract individual country names from the string\\\\n    # This regex tries to capture names that are separated by commas,\\\\n    # or inside parentheses. It\\'s a bit robust.\\\\n    # It also handles \\\\\"u.a.\\\\\" by ignoring it.\\\\n    extracted_countries = re.findall(r\\'[\\\\\\\\w\\\\\\\\s\\\\u00e4\\\\u00f6\\\\u00fc\\\\u00c4\\\\u00d6\\\\u00dc\\\\u00df\\\\\\\\.-]+\\', country_list_string)\\\\n    # Filter out common separators or indicators that aren\\'t country names\\\\n    extracted_countries = [\\\\n        country.strip() for country in extracted_countries\\\\n        if country.strip() and country.strip().lower() not in [\\\\\"u.a.\\\\\", \\\\\"\\\\\"]\\\\n    ]\\\\n    # Further refinement for parenthetical content\\\\n    if \\'(\\' in country_list_string and \\')\\' in country_list_string:\\\\n        parenthetical_content = re.search(r\\'\\\\\\\\((.*?)\\\\\\\\)\\', country_list_string)\\\\n        if parenthetical_content:\\\\n            inner_countries = [c.strip() for c in parenthetical_content.group(1).split(\\',\\')]\\\\n            extracted_countries.extend(inner_countries)\\\\n    # Remove duplicates and refine the list\\\\n    extracted_countries = list(set([re.sub(r\\'\\\\\\\\s*\\\\\\\\(.*\\\\\\\\)\\\\\\\\s*\\', \\'\\', c).strip() for c in extracted_countries]))\\\\n    extracted_countries = [c for c in extracted_countries if c] # Remove empty strings\\\\n\\\\n\\\\n    # 2. Iterate through your mapping table to find matches\\\\n    for canonical_name, aliases_str in mapping_table.items():\\\\n        aliases = [alias.strip() for alias in aliases_str.split(\\',\\')]\\\\n        for extracted in extracted_countries:\\\\n            if extracted in aliases:\\\\n                mapped_countries.add(canonical_name)\\\\n                break # Once a match is found for this canonical name, move to the next one\\\\n\\\\n    return list(mapped_countries)\\\\n\\\\n# Example usage with your provided database strings:\\\\n#print(\\\\\"Before shape\\\\\")\\\\ndb_aggressors = get_all_participants(\\'Parteien_Seite_Aggressor\\')  # Assuming this function returns a list of strings from your database\\\\ndb_defenders = get_all_participants(\\'Parteien_Seite_Verteidiger\\')  # Assuming this function returns a list of strings from your database\\\\n#print(db_strings.head())  # Display the first few rows of the DataFrame\\\\n#print(\\\\\"After shape\\\\\")\\\\n#print(df.head()) #DEBUG first 5 rows\\\\n\\\\n# Start with the original DataFrame (e.g. db_aggressors)\\\\ndf = db_aggressors.copy()\\\\n\\\\n# Map aggressors\\\\ndf[\\'mapped_Parteien_Seite_Aggressor\\'] = df[\\'Parteien_Seite_Aggressor\\'].apply(lambda x: process_country_list(x, kriegsteilnehmer_mapping_red))\\\\nfor idx, mapped_list in df[\\'mapped_Parteien_Seite_Aggressor\\'].items():\\\\n    for country in mapped_list:\\\\n        df.at[idx, country] = \\'Agressor\\'\\\\n\\\\n# Map defenders (use the same DataFrame!)\\\\ndf[\\'mapped_Parteien_Seite_Verteidiger\\'] = db_defenders[\\'Parteien_Seite_Verteidiger\\'].apply(lambda x: process_country_list(x, kriegsteilnehmer_mapping_red))\\\\nfor idx, mapped_list in df[\\'mapped_Parteien_Seite_Verteidiger\\'].items():\\\\n    for country in mapped_list:\\\\n        # Create the column if it does not exist\\\\n        if country not in df.columns:\\\\n            df[country] = np.nan\\\\n        # If already \\'Agressor\\', set to \\'Both\\', else \\'Defender\\'\\\\n        if df.at[idx, country] == \\'Agressor\\':\\\\n            df.at[idx, country] = \\'Both\\'\\\\n        else:\\\\n            df.at[idx, country] = \\'Defender\\'\\\\n\\\\n# Optional: fill NaN with False for all new columns (canonical country names)\\\\n#country_columns = set([country for sublist in df[\\'mapped_Parteien_Seite_Aggressor\\'] for country in sublist])\\\\n#df[list(country_columns)] = df[list(country_columns)].fillna(False)\\\\n\\\\n# Save the DataFrame to a CSV file\\\\n#df.to_csv(\\\\\"normalized_participants.csv\\\\\", index=False)\\\\n\\\\n# Open a connection to your existing database\\\\n# Convert lists to comma-separated strings for database storage\\\\ndf[\\'mapped_Parteien_Seite_Aggressor\\'] = df[\\'mapped_Parteien_Seite_Aggressor\\'].apply(lambda x: \\', \\'.join(x) if isinstance(x, list) else str(x))\\\\ndf[\\'mapped_Parteien_Seite_Verteidiger\\'] = df[\\'mapped_Parteien_Seite_Verteidiger\\'].apply(lambda x: \\', \\'.join(x) if isinstance(x, list) else str(x))\\\\nimport sqlite3\\\\nconn = sqlite3.connect(\\'kriege_datenbank.db\\')\\\\n# Write the DataFrame to a new table, e.g. \\\\\"normalized_participants\\\\\"\\\\ndf.to_sql(\\'KriegeGlobalTeilnehmer\\', conn, if_exists=\\'replace\\', index=False)\\\\nconn.close()\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n# After both loops for aggressor and defender, collect all country columns\\\\n# (they are the columns that are not in the original db_defenders columns or mapped columns)\\\\noriginal_columns = set(db_defenders.columns) | {\\'mapped_Parteien_Seite_Aggressor\\', \\'mapped_Parteien_Seite_Verteidiger\\'}\\\\ncountry_columns = [col for col in df.columns if col not in original_columns]\\\\n\\\\nfrom itertools import permutations\\\\n\\\\nmax_count = 0\\\\nmax_pair = (None, None)\\\\n\\\\nfor country1, country2 in permutations(country_columns, 2):\\\\n    # country1 ist Aggressor, country2 ist Defender in derselben Zeile\\\\n    count = ((df[country1] == \\'Agressor\\') & (df[country2] == \\'Defender\\')).sum()\\\\n    if count > max_count:\\\\n        max_count = count\\\\n        max_pair = (country1, country2)\\\\n\\\\nprint(f\\\\\"The pair of countries most often on different sides (Aggressor/Defender): {max_pair} ({max_count} rows)\\\\\")\\\\n\\\\n# Z\\\\u00e4hle f\\\\u00fcr jedes Land, wie oft es \\\\\"Agressor\\\\\" oder \\\\\"Defender\\\\\" ist\\\\naggressor_counts = {}\\\\ndefender_counts = {}\\\\n\\\\nfor country in country_columns:\\\\n    aggressor_counts[country] = (df[country] == \\'Agressor\\').sum()\\\\n    defender_counts[country] = (df[country] == \\'Defender\\').sum()\\\\n\\\\n# Finde das Land mit den meisten \\\\\"Agressor\\\\\"- und \\\\\"Defender\\\\\"-Eintr\\\\u00e4gen\\\\nmost_aggressor = max(aggressor_counts, key=aggressor_counts.get)\\\\nmost_defender = max(defender_counts, key=defender_counts.get)\\\\n\\\\nprint(f\\\\\"Most frequent Aggressor: {most_aggressor} ({aggressor_counts[most_aggressor]} times)\\\\\")\\\\nprint(f\\\\\"Most frequent Defender: {most_defender} ({defender_counts[most_defender]} times)\\\\\")\\\\n\\\\nboth_counts = {}\\\\n\\\\nfor country in country_columns:\\\\n    both_counts[country] = aggressor_counts[country] + defender_counts[country]\\\\n\\\\nmost_both = max(both_counts, key=both_counts.get)\\\\nprint(f\\\\\"Country most often involved as both Aggressor and Defender: {most_both} ({both_counts[most_both]} times)\\\\\")\\\\n\\\\n\\\\nboth_role_counts = {}\\\\n\\\\nfor country in country_columns:\\\\n    both_role_counts[country] = (df[country] == \\'Both\\').sum()\\\\n\\\\n# Sort and print the results\\\\nfor country, count in sorted(both_role_counts.items(), key=lambda x: x[1], reverse=True):\\\\n    if count > 0:\\\\n        print(f\\\\\"{country}: {count} times as Both\\\\\")\\\\n\\\\n\\\\n# Bar_chart_race Kriegsteilnahmen\\\\n# 1. W\\\\u00e4hle die relevanten Spalten aus\\\\n# Annahme: \\'Startjahr\\' ist numerisch, country_columns enth\\\\u00e4lt alle L\\\\u00e4nder-Spalten\\\\ndf_bcr = df[[\\'Startjahr\\'] + country_columns].copy()\\\\n\\\\n# 2. Ersetze alle Nicht-NaN-Werte durch 1 (Beteiligung), sonst 0\\\\nfor country in country_columns:\\\\n    df_bcr[country] = df_bcr[country].notna().astype(int)\\\\n\\\\n# 3. Gruppiere nach Jahr und summiere die Beteiligungen\\\\ndf_bcr_grouped = df_bcr.groupby(\\'Startjahr\\')[country_columns].sum()\\\\ndf_bcr_cumulative = df_bcr_grouped.cumsum()\\\\n\\\\n# Optional: Sortiere die Jahre aufsteigend\\\\ndf_bcr_cumulative = df_bcr_cumulative.sort_index()\\\\n\\\\n# 4. Speichere das Ergebnis f\\\\u00fcr bar_chart_race\\\\ndf_bcr_cumulative.to_csv(\\\\\"barchartrace_countries_by_year.csv\\\\\")\\\\n\\\\n#print(df_bcr_grouped.head())\\\\n\\\\n\\\\n\\\\n# Bar_chart_race Kriegsopferzahlen\\\\n# 1. Prepare a DataFrame with Startjahr, Opferzahlen_Gesamt_bis, and country columns\\\\ndf_opfer = df[[\\'Startjahr\\', \\'Opferzahlen_Gesamt_bis\\'] + country_columns].copy()\\\\n\\\\n# 2. For each country, set value to Opferzahlen_Gesamt_bis if participating, else 0\\\\nfor country in country_columns:\\\\n    df_opfer[country] = df_opfer[country].notna().astype(int) * df_opfer[\\'Opferzahlen_Gesamt_bis\\'].fillna(0)\\\\n\\\\n# 3. Group by year and sum\\\\ndf_opfer_grouped = df_opfer.groupby(\\'Startjahr\\')[country_columns].sum()\\\\n\\\\n# 4. Cumulative sum over years\\\\ndf_opfer_cumulative = df_opfer_grouped.cumsum().sort_index()\\\\n\\\\n# 5. Save for bar_chart_race\\\\ndf_opfer_cumulative.to_csv(\\\\\"barchartrace_countries_by_opferzahlen.csv\\\\\")\\\\n#print(df_opfer_cumulative.head())\", \"timestamp\": \"2025-06-30T18:16:20+0200\"}'}, {'type': 'assistant', 'content': '{\"tool\": \"read_folder_file\", \"args\": {\"name\": \"SamplePy/analyze_import2.py\"}}'}, {'type': 'environment', 'content': '{\"tool_executed\": true, \"result\": \"import csv\\\\nimport sqlite3\\\\nfrom collections import Counter # Um Duplikate leicht zu z\\\\u00e4hlen\\\\n\\\\n# --- Konfiguration ---\\\\nCSV_FILE_PATH = \\'China.csv\\'\\\\nDB_FILE_PATH = \\'kriege_datenbank.db\\'\\\\nTABLE_NAME = \\'KriegeChina\\'\\\\nCSV_KRIEG_COLUMN_INDEX = 0\\\\nDB_KRIEG_COLUMN_NAME = \\'Krieg\\'\\\\nEXPECTED_COLUMNS_IN_DATA = 14 # Die Anzahl der Spalten in deinen Datenzeilen\\\\n\\\\ndef compare_csv_and_db_wars():\\\\n    csv_war_list_all = [] # Liste aller Kriegsnamen aus der CSV\\\\n    csv_skipped_rows = 0\\\\n\\\\n    print(f\\\\\"Lese Kriege aus CSV-Datei: {CSV_FILE_PATH}\\\\\")\\\\n    try:\\\\n        with open(CSV_FILE_PATH, mode=\\'r\\', encoding=\\'utf-8-sig\\') as csvfile:\\\\n            csv_reader = csv.reader(csvfile)\\\\n            header = next(csv_reader)\\\\n\\\\n            for i, row in enumerate(csv_reader):\\\\n                current_row_num_in_file = i + 2\\\\n                if not any(field.strip() for field in row):\\\\n                    csv_skipped_rows +=1\\\\n                    continue\\\\n                if len(row) != EXPECTED_COLUMNS_IN_DATA:\\\\n                    print(f\\\\\"Info CSV: Zeile {current_row_num_in_file} hat {len(row)} Spalten, erwartet {EXPECTED_COLUMNS_IN_DATA}. \\\\u00dcbersprungen f\\\\u00fcr diesen Vergleich.\\\\\")\\\\n                    csv_skipped_rows +=1\\\\n                    continue\\\\n                try:\\\\n                    war_name = row[CSV_KRIEG_COLUMN_INDEX].strip()\\\\n                    if war_name: # Nur hinzuf\\\\u00fcgen, wenn der Name nicht leer ist\\\\n                        csv_war_list_all.append(war_name)\\\\n                    else:\\\\n                        print(f\\\\\"Info CSV: Kriegsname in Zeile {current_row_num_in_file} ist leer.\\\\\")\\\\n                        csv_skipped_rows +=1\\\\n                except IndexError:\\\\n                    print(f\\\\\"Fehler CSV: Zeile {current_row_num_in_file} hat nicht gen\\\\u00fcgend Spalten f\\\\u00fcr Kriegsnamen.\\\\\")\\\\n                    csv_skipped_rows +=1\\\\n                    continue\\\\n    except FileNotFoundError:\\\\n        print(f\\\\\"Fehler: CSV-Datei \\'{CSV_FILE_PATH}\\' nicht gefunden.\\\\\")\\\\n        return\\\\n    except Exception as e:\\\\n        print(f\\\\\"Fehler beim Lesen der CSV: {e}\\\\\")\\\\n        return\\\\n\\\\n    print(f\\\\\"{len(csv_war_list_all)} Kriege (potenziell mit Duplikaten) aus CSV geladen (nach \\\\u00dcberspringen von {csv_skipped_rows} Zeilen).\\\\\")\\\\n\\\\n    # Z\\\\u00e4hle Duplikate in der CSV\\\\n    csv_war_counts = Counter(csv_war_list_all)\\\\n    csv_unique_wars_set = set(csv_war_list_all)\\\\n    csv_duplicate_names = {name: count for name, count in csv_war_counts.items() if count > 1}\\\\n\\\\n    print(f\\\\\"{len(csv_unique_wars_set)} einzigartige Kriegsnamen in der CSV-Liste.\\\\\")\\\\n    if csv_duplicate_names:\\\\n        print(f\\\\\"{len(csv_duplicate_names)} Kriegsname(n) kommen in der CSV mehrfach vor:\\\\\")\\\\n        for name, count in csv_duplicate_names.items():\\\\n            print(f\\\\\"  - \\'{name}\\' (kommt {count} Mal vor)\\\\\")\\\\n    else:\\\\n        print(\\\\\"Keine Duplikate (basierend auf Kriegsnamen) in der CSV-Liste gefunden.\\\\\")\\\\n\\\\n    # --- Aus der Datenbank lesen ---\\\\n    db_war_list_all = []\\\\n    db_row_count_actual = 0\\\\n    conn_db_count = None\\\\n    try:\\\\n        conn_db_count = sqlite3.connect(DB_FILE_PATH)\\\\n        cursor_db_count = conn_db_count.cursor()\\\\n        # Tats\\\\u00e4chliche Zeilenzahl ermitteln\\\\n        cursor_db_count.execute(f\\\\\"SELECT COUNT(*) FROM {TABLE_NAME}\\\\\")\\\\n        db_row_count_actual = cursor_db_count.fetchone()[0]\\\\n\\\\n        # Alle Kriegsnamen aus der DB holen\\\\n        cursor_db_count.execute(f\\\\\"SELECT \\\\\\\\\\\\\"{DB_KRIEG_COLUMN_NAME}\\\\\\\\\\\\\" FROM {TABLE_NAME}\\\\\")\\\\n        for row in cursor_db_count:\\\\n            if row[0] is not None: # Ignoriere NULL-Werte f\\\\u00fcr den Kriegsnamen, falls vorhanden\\\\n                 db_war_list_all.append(row[0].strip())\\\\n            else:\\\\n                print(\\\\\"Info DB: Ein Kriegsname in der DB ist NULL.\\\\\")\\\\n        conn_db_count.close()\\\\n    except sqlite3.Error as e:\\\\n        print(f\\\\\"SQLite Fehler beim Lesen der DB: {e}\\\\\")\\\\n        if conn_db_count: conn_db_count.close()\\\\n        return\\\\n\\\\n    print(f\\\\\"\\\\\\\\nDatenbank-Analyse:\\\\\")\\\\n    print(f\\\\\"Tats\\\\u00e4chliche Zeilenanzahl in DB-Tabelle \\'{TABLE_NAME}\\' laut COUNT(*): {db_row_count_actual}\\\\\")\\\\n    print(f\\\\\"{len(db_war_list_all)} Kriegsnamen aus DB geladen (nach .strip() und ohne NULLs).\\\\\")\\\\n\\\\n    db_war_counts = Counter(db_war_list_all)\\\\n    db_unique_wars_set = set(db_war_list_all)\\\\n    db_duplicate_names = {name: count for name, count in db_war_counts.items() if count > 1}\\\\n\\\\n    print(f\\\\\"{len(db_unique_wars_set)} einzigartige Kriegsnamen in der DB-Liste (nach .strip()).\\\\\")\\\\n    if db_duplicate_names:\\\\n        print(f\\\\\"ACHTUNG: {len(db_duplicate_names)} Kriegsname(n) kommen in der DB-Liste MEHRFACH vor (sollte bei PRIMARY KEY nicht sein, es sei denn .strip() f\\\\u00fchrt zu Kollisionen):\\\\\")\\\\n        for name, count in db_duplicate_names.items():\\\\n            print(f\\\\\"  - \\'{name}\\' (kommt {count} Mal vor in der DB-Liste nach .strip())\\\\\")\\\\n    else:\\\\n        print(\\\\\"Keine Duplikate in der DB-Liste der Kriegsnamen gefunden (nach .strip()).\\\\\")\\\\n\\\\n\\\\n    # --- Vergleiche die Sets ---\\\\n    print(\\\\\"\\\\\\\\nVergleich der einzigartigen Kriegsnamen-Sets:\\\\\")\\\\n    missing_in_db_set = csv_unique_wars_set - db_unique_wars_set\\\\n    missing_in_csv_set = db_unique_wars_set - csv_unique_wars_set\\\\n\\\\n    if missing_in_db_set:\\\\n        print(f\\\\\"\\\\\\\\n{len(missing_in_db_set)} EINZIGARTIGE Kriege sind im CSV-Set, aber NICHT im DB-Set:\\\\\")\\\\n        for war in sorted(list(missing_in_db_set)):\\\\n            print(f\\\\\"  - \\'{war}\\'\\\\\")\\\\n    else:\\\\n        print(\\\\\"\\\\\\\\nAlle einzigartigen Kriege aus dem CSV-Set sind auch im DB-Set vorhanden.\\\\\")\\\\n\\\\n    if missing_in_csv_set:\\\\n        print(f\\\\\"\\\\\\\\n{len(missing_in_csv_set)} EINZIGARTIGE Kriege sind im DB-Set, aber NICHT im CSV-Set (sollte nicht passieren, wenn CSV die Quelle ist):\\\\\")\\\\n        for war in sorted(list(missing_in_csv_set)):\\\\n            print(f\\\\\"  - \\'{war}\\'\\\\\")\\\\n    else:\\\\n        print(\\\\\"\\\\\\\\nAlle einzigartigen Kriege aus dem DB-Set sind auch im CSV-Set vorhanden.\\\\\")\\\\n\\\\n    print(\\\\\"\\\\\\\\n--- Zusammenfassung der Z\\\\u00e4hlungen ---\\\\\")\\\\n    print(f\\\\\"CSV: {len(csv_war_list_all)} gelesene Namen (potenziell mit Duplikaten)\\\\\")\\\\n    print(f\\\\\"CSV: {len(csv_unique_wars_set)} einzigartige Namen\\\\\")\\\\n    print(f\\\\\"DB (COUNT(*)): {db_row_count_actual} Zeilen\\\\\")\\\\n    print(f\\\\\"DB: {len(db_war_list_all)} gelesene Namen (ignoriert NULLs, .strip() angewendet)\\\\\")\\\\n    print(f\\\\\"DB: {len(db_unique_wars_set)} einzigartige Namen (nach .strip())\\\\\")\\\\n\\\\n    if len(csv_unique_wars_set) == db_row_count_actual and not missing_in_db_set and not missing_in_csv_set and not csv_duplicate_names:\\\\n        print(\\\\\"\\\\\\\\nPerfekte \\\\u00dcbereinstimmung zwischen einzigartigen CSV-Namen und DB-Zeilenanzahl, keine Duplikate in CSV.\\\\\")\\\\n    elif len(csv_war_list_all) - len(csv_duplicate_names) == db_row_count_actual and not missing_in_db_set and not missing_in_csv_set :\\\\n         # Diese Logik ist nicht ganz korrekt, wenn csv_duplicate_names die Anzahl der Namen ist, nicht die Anzahl der Duplikat-Instanzen\\\\n         num_lost_to_duplicates = sum(count - 1 for count in csv_duplicate_names.values())\\\\n         if len(csv_war_list_all) - num_lost_to_duplicates == db_row_count_actual:\\\\n            print(f\\\\\"\\\\\\\\nDie Differenz zwischen CSV-Rohdaten ({len(csv_war_list_all)}) und DB-Zeilen ({db_row_count_actual}) scheint durch {num_lost_to_duplicates} Duplikat-Instanzen in der CSV erkl\\\\u00e4rt zu werden.\\\\\")\\\\n\\\\n\\\\nif __name__ == \\'__main__\\':\\\\n    compare_csv_and_db_wars()\", \"timestamp\": \"2025-06-30T18:16:22+0200\"}'}, {'type': 'assistant', 'content': '{\"tool\": \"read_folder_file\", \"args\": {\"name\": \"SamplePy/database_operations.py\"}}'}, {'type': 'environment', 'content': '{\"tool_executed\": true, \"result\": \"import sqlite3\\\\nimport pandas as pd\\\\n\\\\ndef reset_database(table):\\\\n    conn = sqlite3.connect(\\\\\"kriege_datenbank.db\\\\\")\\\\n    cursor = conn.cursor()\\\\n    \\\\n    # L\\\\u00f6sche die Tabelle, falls sie existiert\\\\n    cursor.execute(\\\\\"DROP TABLE IF EXISTS table\\\\\")\\\\n    \\\\n    # Erstelle die Tabelle neu\\\\n    cursor.execute(\\\\\"\\\\\"\\\\\"\\\\n        CREATE TABLE table (\\\\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\\\\n            Krieg_Name TEXT NOT NULL,\\\\n            Start_Jahr INTEGER,\\\\n            End_Jahr INTEGER\\\\n        )\\\\n    \\\\\"\\\\\"\\\\\")\\\\n    \\\\n    conn.commit()\\\\n    conn.close()\\\\n\\\\ndef delete_duplicates_from_wars():\\\\n    conn = sqlite3.connect(\\\\\"kriege_datenbank.db\\\\\")\\\\n    cursor = conn.cursor()\\\\n\\\\n    # L\\\\u00f6sche Duplikate basierend auf name, Start_Jahr und End_Jahr\\\\n    cursor.execute(\\\\\"\\\\\"\\\\\"\\\\n        DELETE FROM kriege\\\\n        WHERE rowid NOT IN (\\\\n            SELECT MIN(rowid)\\\\n            FROM kriege\\\\n            GROUP BY Krieg_Name, Start_Jahr, End_Jahr\\\\n        )\\\\n    \\\\\"\\\\\"\\\\\")\\\\n    conn.commit()\\\\n    conn.close()\\\\n\\\\ndef insert_war(Krieg_Name, Start_Jahr, End_Jahr):\\\\n    conn = sqlite3.connect(\\\\\"kriege_datenbank.db\\\\\")\\\\n    cursor = conn.cursor()\\\\n    \\\\n    cursor.execute(\\\\\"\\\\\"\\\\\"\\\\n        INSERT INTO kriege (Krieg_Name, Start_Jahr, End_Jahr)\\\\n        VALUES (?, ?, ?)\\\\n    \\\\\"\\\\\"\\\\\", (Krieg_Name, Start_Jahr, End_Jahr))\\\\n    \\\\n    conn.commit()\\\\n    conn.close()\\\\n\\\\ndef get_all_wars():\\\\n    conn = sqlite3.connect(\\\\\"kriege_datenbank.db\\\\\")\\\\n    cursor = conn.cursor()\\\\n    \\\\n    cursor.execute(\\\\\"SELECT * FROM kriege\\\\\")\\\\n    wars = cursor.fetchall()\\\\n    \\\\n    conn.close()\\\\n    return wars\\\\n\\\\n\\\\ndef get_all_participants(column_name):\\\\n    # Connect to the SQLite database\\\\n    conn = sqlite3.connect(\\'kriege_datenbank.db\\')\\\\n\\\\n    # Read a table into a DataFrame\\\\n    df = pd.read_sql_query(f\\\\\"SELECT * FROM KriegeGesamt\\\\\", conn)\\\\n    #print(df.shape)  # Display the first few rows of the DataFrame\\\\n    #print(df.head()) #DEBUG first 5 rows\\\\n\\\\n    # Close the connection when done\\\\n    conn.close()\\\\n    return df\", \"timestamp\": \"2025-06-30T18:16:23+0200\"}'}, {'type': 'assistant', 'content': '{\"tool\": \"read_folder_file\", \"args\": {\"name\": \"SamplePy/wars_barchartrace.py\"}}'}, {'type': 'environment', 'content': '{\"tool_executed\": true, \"result\": \"import bar_chart_race as bcr\\\\nimport pandas as pd\\\\n\\\\n# Example dataframe (wide format, index = time, columns = categories)\\\\n#df = pd.read_csv(\\'barchartrace_countries_by_year.csv\\', index_col=\\'Startjahr\\', parse_dates=True)\\\\ndf = pd.read_csv(\\'barchartrace_countries_by_opferzahlen.csv\\', index_col=\\'Startjahr\\', parse_dates=True)\\\\n\\\\nbcr.bar_chart_race(\\\\n    df=df,\\\\n    #filename=\\'wars_race.mp4\\',\\\\n    filename=\\'wars_death_race.mp4\\',\\\\n    orientation=\\'h\\',\\\\n    sort=\\'desc\\',\\\\n    n_bars=20,\\\\n    fixed_order=False,\\\\n    fixed_max=True,\\\\n    steps_per_period=1,\\\\n    interpolate_period=True,\\\\n    period_length=500,\\\\n    period_label={\\'x\\': .95, \\'y\\': .15, \\'ha\\': \\'right\\', \\'va\\': \\'center\\', \\'fontsize\\': 22, \\'color\\': \\'black\\', \\'bbox\\': dict(facecolor=\\'white\\', edgecolor=\\'black\\', boxstyle=\\'round,pad=0.5\\')},\\\\n    period_fmt=\\'{x:.0f}\\',  # Show only the year\\\\n    title=\\'Vicitims by Wars Participating Countries\\',\\\\n    #title=\\'War Count by by Country\\',\\\\n    bar_size=.95,\\\\n    cmap=\\'dark12\\',\\\\n    filter_column_colors=True\\\\n)\", \"timestamp\": \"2025-06-30T18:16:24+0200\"}'}, {'type': 'assistant', 'content': '{\"tool\": \"terminate\", \"args\": {\"message\": \"This project is set up to analyze historical wars using data from a CSV and a database. Below is an overview of the functionality provided by each script:\\\\n\\\\n### Files and Their Descriptions:\\\\n\\\\n1. **NormalizeCountries.py**:\\\\n   - This script processes country names from a database field and maps them to standardized names using a mapping table.\\\\n   - It performs data transformation including cleaning country lists, mapping them to canonical names, and updating a database based on these mappings.\\\\n   - The script outputs processed data to both CSV files and a SQLite database.\\\\n\\\\n2. **analyze_import2.py**:\\\\n   - It compares war names between a CSV file and a SQLite database to identify duplicates and mismatches.\\\\n   - Outputs the analysis of unique and duplicate war names from both sources to help verify data integrity and consistency.\\\\n\\\\n3. **database_operations.py**:\\\\n   - Contains functions for interacting with the SQLite database, such as resetting tables, deleting duplicates, inserting new records, and retrieving data.\\\\n   - Simplifies repetitive database tasks to streamline data handling processes.\\\\n\\\\n4. **wars_barchartrace.py**:\\\\n   - Uses the bar_chart_race library to create visual bar chart race animations representing war-related statistics over time.\\\\n   - The script reads preprocessed data and generates animations showcasing the evolution of countries\\' involvement or victim counts in wars.\\\\n\\\\n### Additional Context:\\\\n- **Data Flows**: Data is pulled from a CSV and manipulated to ensure consistency before being saved into the database. Each module has a specific role ranging from data normalization, verification, and visual representation.\\\\n- **Database**: SQLite is used for storing and querying war data. This helps in managing persistent state and allowing complex queries to be run on the dataset.\\\\n- **Visualization**: The visualizations generated help in understanding trends and patterns in war data over time, pointed by either the count of wars or the human impact through victim counts.\\\\n\\\\nThis project combines data engineering, transformation, and visualization to offer insights into historical wars and their participants effectively.\"}}'}, {'type': 'environment', 'content': '{\"tool_executed\": true, \"result\": \"This project is set up to analyze historical wars using data from a CSV and a database. Below is an overview of the functionality provided by each script:\\\\n\\\\n### Files and Their Descriptions:\\\\n\\\\n1. **NormalizeCountries.py**:\\\\n   - This script processes country names from a database field and maps them to standardized names using a mapping table.\\\\n   - It performs data transformation including cleaning country lists, mapping them to canonical names, and updating a database based on these mappings.\\\\n   - The script outputs processed data to both CSV files and a SQLite database.\\\\n\\\\n2. **analyze_import2.py**:\\\\n   - It compares war names between a CSV file and a SQLite database to identify duplicates and mismatches.\\\\n   - Outputs the analysis of unique and duplicate war names from both sources to help verify data integrity and consistency.\\\\n\\\\n3. **database_operations.py**:\\\\n   - Contains functions for interacting with the SQLite database, such as resetting tables, deleting duplicates, inserting new records, and retrieving data.\\\\n   - Simplifies repetitive database tasks to streamline data handling processes.\\\\n\\\\n4. **wars_barchartrace.py**:\\\\n   - Uses the bar_chart_race library to create visual bar chart race animations representing war-related statistics over time.\\\\n   - The script reads preprocessed data and generates animations showcasing the evolution of countries\\' involvement or victim counts in wars.\\\\n\\\\n### Additional Context:\\\\n- **Data Flows**: Data is pulled from a CSV and manipulated to ensure consistency before being saved into the database. Each module has a specific role ranging from data normalization, verification, and visual representation.\\\\n- **Database**: SQLite is used for storing and querying war data. This helps in managing persistent state and allowing complex queries to be run on the dataset.\\\\n- **Visualization**: The visualizations generated help in understanding trends and patterns in war data over time, pointed by either the count of wars or the human impact through victim counts.\\\\n\\\\nThis project combines data engineering, transformation, and visualization to offer insights into historical wars and their participants effectively.\\\\nTerminating...\", \"timestamp\": \"2025-06-30T18:16:36+0200\"}'}]\n"
          ]
        }
      ],
      "source": [
        " \n",
        "    folder = \"SamplePy\"  # Change this to any folder you want to analyze\n",
        "\n",
        "    # First, we'll define our tools using decorators\n",
        "    @register_tool(tags=[\"file_operations\", \"read\"])\n",
        "    def read_project_file(name: str) -> str:\n",
        "        \"\"\"Reads and returns the content of a specified project file.\n",
        "\n",
        "        Opens the file in read mode and returns its entire contents as a string.\n",
        "        Raises FileNotFoundError if the file doesn't exist.\n",
        "\n",
        "        Args:\n",
        "            name: The name of the file to read\n",
        "\n",
        "        Returns:\n",
        "            The contents of the file as a string\n",
        "        \"\"\"\n",
        "        with open(name, \"r\") as f:\n",
        "            return f.read()\n",
        "\n",
        "    @register_tool(tags=[\"file_operations\", \"list\"])\n",
        "    def list_project_files() -> List[str]:\n",
        "        \"\"\"Lists all Python files in the current project directory.\n",
        "\n",
        "        Scans the current directory and returns a sorted list of all files\n",
        "        that end with '.py'.\n",
        "\n",
        "        Returns:\n",
        "            A sorted list of Python filenames\n",
        "        \"\"\"\n",
        "        return sorted([file for file in os.listdir(\".\")\n",
        "                      if file.endswith(\".py\")])\n",
        "\n",
        "    @register_tool(tags=[\"file_operations\", \"list\"])\n",
        "    def list_folder_files() -> List[str]:\n",
        "        \"\"\"Lists all Python files in the {folder} directory.\n",
        "\n",
        "        Scans the {folder} directory and returns a sorted list of all files\n",
        "        that end with '.py'.\n",
        "\n",
        "        Returns:\n",
        "            A sorted list of Python filenames\n",
        "        \"\"\"\n",
        "        return sorted([\n",
        "            os.path.join(folder, file)\n",
        "            for file in os.listdir(folder)\n",
        "            if file.endswith(\".py\")\n",
        "        ])\n",
        "\n",
        "    @register_tool(tags=[\"file_operations\", \"list\"])\n",
        "    def read_folder_file(name: str) -> List[str]:\n",
        "        \"\"\"Reads and returns the content of a specified project file from the {folder} directory\n",
        "\n",
        "        Opens the file in read mode and returns its entire contents as a string.\n",
        "        Raises FileNotFoundError if the file doesn't exist.\n",
        "\n",
        "        Args:\n",
        "            name: The name of the file to read\n",
        "\n",
        "        Returns:\n",
        "            The contents of the file as a string\n",
        "        \"\"\"\n",
        "        with open(name, \"r\") as f:\n",
        "            return f.read()\n",
        "\n",
        "    @register_tool(tags=[\"system\"], terminal=True)\n",
        "    def terminate(message: str) -> str:\n",
        "        \"\"\"Terminates the agent's execution with a final message.\n",
        "\n",
        "        Args:\n",
        "            message: The final message to return before terminating\n",
        "\n",
        "        Returns:\n",
        "            The message with a termination note appended\n",
        "        \"\"\"\n",
        "        return f\"{message}\\nTerminating...\"\n",
        "\n",
        "\n",
        "    # Define the agent's goals\n",
        "    goals = [\n",
        "        Goal(priority=1, \n",
        "             name=\"Gather Information\", \n",
        "             description=f\"Read each Python file in the {folder} directory.\"),\n",
        "        Goal(priority=1, \n",
        "             name=\"Terminate\", \n",
        "             description=\"Call the terminate call when you have read all the files and provide the content of the README in the terminate message.\")\n",
        "    ]\n",
        "\n",
        "    # Create an agent instance with tag-filtered actions\n",
        "    agent = Agent(\n",
        "        goals=goals,\n",
        "        agent_language=AgentFunctionCallingActionLanguage(),\n",
        "        # The ActionRegistry now automatically loads tools with these tags\n",
        "        action_registry=PythonActionRegistry(tags=[\"file_operations\", \"system\"]),\n",
        "        generate_response=generate_response,\n",
        "        environment=Environment()\n",
        "    )   \n",
        "\n",
        "    # Run the agent with user input\n",
        "    user_input = \"Write a README for this project.\"\n",
        "    final_memory = agent.run(user_input)\n",
        "\n",
        "    # Extract the README content from the final memory\n",
        "    memories = final_memory.get_memories()\n",
        "    file_summaries = []\n",
        "\n",
        "    # Collect Action Results for read_folder_file (just file names, no content)\n",
        "    for i, mem in enumerate(memories):\n",
        "        if mem[\"type\"] == \"assistant\":\n",
        "            try:\n",
        "                action = json.loads(mem[\"content\"])\n",
        "                if action.get(\"tool\") == \"read_folder_file\":\n",
        "                    file_name = action[\"args\"][\"name\"]\n",
        "                    if file_name not in file_summaries:\n",
        "                        file_summaries.append(f\"- {file_name}\")\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "    # Find the terminate message for the README summary\n",
        "    for mem in reversed(memories):\n",
        "        if mem[\"type\"] == \"environment\":\n",
        "            try:\n",
        "                result = json.loads(mem[\"content\"])\n",
        "                if result.get(\"tool_executed\") and isinstance(result.get(\"result\"), str):\n",
        "                    content = result[\"result\"]\n",
        "                    if content.strip().endswith(\"Terminating...\"):\n",
        "                        readme_content = content.replace(\"Terminating...\", \"\").strip()\n",
        "                        break\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "    # Combine everything into the README\n",
        "    full_readme = \"# Project README\\n\\n\"\n",
        "    if readme_content:\n",
        "        full_readme += readme_content + \"\\n\\n\"\n",
        "    if file_summaries:\n",
        "        full_readme += \"## Python Files\\n\\n\" + \"\\n\".join(file_summaries)\n",
        "\n",
        "    if full_readme.strip():\n",
        "        with open(os.path.join(folder, \"README_agent.md\"), \"w\") as f:\n",
        "            f.write(full_readme)\n",
        "        print(f\"README_agent.md saved in {folder}.\")\n",
        "    else:\n",
        "        print(\"README content not found in memory.\")\n",
        "\n",
        "    # Add this before your extraction loop for debugging if needed - it prints all environment memories\n",
        "    #for mem in reversed(memories):\n",
        "        print(mem[\"type\"], mem[\"content\"])\n",
        "\n",
        "    # Print the final memory\n",
        "    print(memories)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
