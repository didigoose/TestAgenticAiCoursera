{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEYrzG2vB8Ip"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting litellm\n",
            "  Using cached litellm-1.73.6-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting aiohttp>=3.10 (from litellm)\n",
            "  Using cached aiohttp-3.12.13-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
            "Collecting click (from litellm)\n",
            "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting httpx>=0.23.0 (from litellm)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in ./.venv/lib/python3.9/site-packages (from litellm) (8.7.0)\n",
            "Collecting jinja2<4.0.0,>=3.1.2 (from litellm)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting jsonschema<5.0.0,>=4.22.0 (from litellm)\n",
            "  Using cached jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting openai>=1.68.2 (from litellm)\n",
            "  Using cached openai-1.93.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting pydantic<3.0.0,>=2.0.0 (from litellm)\n",
            "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
            "Collecting python-dotenv>=0.2.0 (from litellm)\n",
            "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tiktoken>=0.7.0 (from litellm)\n",
            "  Using cached tiktoken-0.9.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
            "Collecting tokenizers (from litellm)\n",
            "  Using cached tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2<4.0.0,>=3.1.2->litellm)\n",
            "  Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
            "Collecting attrs>=22.2.0 (from jsonschema<5.0.0,>=4.22.0->litellm)\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.22.0->litellm)\n",
            "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.22.0->litellm)\n",
            "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.22.0->litellm)\n",
            "  Using cached rpds_py-0.25.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.0.0->litellm)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.0.0->litellm)\n",
            "  Using cached pydantic_core-2.33.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in ./.venv/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.0.0->litellm) (4.14.0)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.0.0->litellm)\n",
            "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp>=3.10->litellm)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp>=3.10->litellm)\n",
            "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp>=3.10->litellm)\n",
            "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp>=3.10->litellm)\n",
            "  Using cached frozenlist-1.7.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.10->litellm)\n",
            "  Using cached multidict-6.6.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp>=3.10->litellm)\n",
            "  Using cached propcache-0.3.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.10->litellm)\n",
            "  Using cached yarl-1.20.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (73 kB)\n",
            "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp>=3.10->litellm)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting anyio (from httpx>=0.23.0->litellm)\n",
            "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting certifi (from httpx>=0.23.0->litellm)\n",
            "  Using cached certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting httpcore==1.* (from httpx>=0.23.0->litellm)\n",
            "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.23.0->litellm)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.9/site-packages (from importlib-metadata>=6.8.0->litellm) (3.23.0)\n",
            "Collecting distro<2,>=1.7.0 (from openai>=1.68.2->litellm)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.68.2->litellm)\n",
            "  Using cached jiter-0.10.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
            "Collecting sniffio (from openai>=1.68.2->litellm)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting tqdm>4 (from openai>=1.68.2->litellm)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.9/site-packages (from anyio->httpx>=0.23.0->litellm) (1.3.0)\n",
            "Collecting regex>=2022.1.18 (from tiktoken>=0.7.0->litellm)\n",
            "  Using cached regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\n",
            "Collecting requests>=2.26.0 (from tiktoken>=0.7.0->litellm)\n",
            "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests>=2.26.0->tiktoken>=0.7.0->litellm)\n",
            "  Using cached charset_normalizer-3.4.2-cp39-cp39-macosx_10_9_universal2.whl.metadata (35 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken>=0.7.0->litellm)\n",
            "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers->litellm)\n",
            "  Using cached huggingface_hub-0.33.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm)\n",
            "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm)\n",
            "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (25.0)\n",
            "Collecting pyyaml>=5.1 (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm)\n",
            "  Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm)\n",
            "  Using cached hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl.metadata (879 bytes)\n",
            "Using cached litellm-1.73.6-py3-none-any.whl (8.5 MB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
            "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
            "Using cached pydantic_core-2.33.2-cp39-cp39-macosx_11_0_arm64.whl (1.9 MB)\n",
            "Using cached aiohttp-3.12.13-cp39-cp39-macosx_11_0_arm64.whl (467 kB)\n",
            "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Using cached multidict-6.6.2-cp39-cp39-macosx_11_0_arm64.whl (44 kB)\n",
            "Using cached yarl-1.20.1-cp39-cp39-macosx_11_0_arm64.whl (89 kB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Using cached frozenlist-1.7.0-cp39-cp39-macosx_11_0_arm64.whl (47 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
            "Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl (12 kB)\n",
            "Using cached openai-1.93.0-py3-none-any.whl (755 kB)\n",
            "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached jiter-0.10.0-cp39-cp39-macosx_11_0_arm64.whl (312 kB)\n",
            "Using cached propcache-0.3.2-cp39-cp39-macosx_11_0_arm64.whl (43 kB)\n",
            "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Using cached rpds_py-0.25.1-cp39-cp39-macosx_11_0_arm64.whl (359 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Using cached tiktoken-0.9.0-cp39-cp39-macosx_11_0_arm64.whl (1.0 MB)\n",
            "Using cached regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\n",
            "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "Using cached charset_normalizer-3.4.2-cp39-cp39-macosx_10_9_universal2.whl (201 kB)\n",
            "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Using cached certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
            "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Using cached tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
            "Using cached huggingface_hub-0.33.1-py3-none-any.whl (515 kB)\n",
            "Using cached hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
            "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
            "Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n",
            "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: urllib3, typing-inspection, tqdm, sniffio, rpds-py, regex, pyyaml, python-dotenv, pydantic-core, propcache, multidict, MarkupSafe, jiter, idna, hf-xet, h11, fsspec, frozenlist, filelock, distro, click, charset_normalizer, certifi, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, requests, referencing, pydantic, jinja2, httpcore, anyio, aiosignal, tiktoken, jsonschema-specifications, huggingface-hub, httpx, aiohttp, tokenizers, openai, jsonschema, litellm\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m43/44\u001b[0m [litellm][openai]]ace-hub]er]\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/py_compile.py\", line 144, in compile\n",
            "    code = loader.source_to_code(source_bytes, dfile or file,\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 913, in source_to_code\n",
            "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
            "  File \"/Users/dietmarklotz/DataScience/TestAgenticAiCoursera/.venv/lib/python3.9/site-packages/litellm/proxy/guardrails/guardrail_hooks/pangea.py\", line 138\n",
            "    match call_type:\n",
            "          ^\n",
            "SyntaxError: invalid syntax\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/compileall.py\", line 238, in compile_file\n",
            "    ok = py_compile.compile(fullname, cfile, dfile, True,\n",
            "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/py_compile.py\", line 150, in compile\n",
            "    raise py_exc\n",
            "py_compile.PyCompileError:   File \"/Users/dietmarklotz/DataScience/TestAgenticAiCoursera/.venv/lib/python3.9/site-packages/litellm/proxy/guardrails/guardrail_hooks/pangea.py\", line 138\n",
            "    match call_type:\n",
            "          ^\n",
            "SyntaxError: invalid syntax\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/dietmarklotz/DataScience/TestAgenticAiCoursera/.venv/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 105, in _run_wrapper\n",
            "    status = _inner_run()\n",
            "  File \"/Users/dietmarklotz/DataScience/TestAgenticAiCoursera/.venv/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 96, in _inner_run\n",
            "    return self.run(options, args)\n",
            "  File \"/Users/dietmarklotz/DataScience/TestAgenticAiCoursera/.venv/lib/python3.9/site-packages/pip/_internal/cli/req_command.py\", line 68, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/Users/dietmarklotz/DataScience/TestAgenticAiCoursera/.venv/lib/python3.9/site-packages/pip/_internal/commands/install.py\", line 459, in run\n",
            "    installed = install_given_reqs(\n",
            "  File \"/Users/dietmarklotz/DataScience/TestAgenticAiCoursera/.venv/lib/python3.9/site-packages/pip/_internal/req/__init__.py\", line 83, in install_given_reqs\n",
            "    requirement.install(\n",
            "  File \"/Users/dietmarklotz/DataScience/TestAgenticAiCoursera/.venv/lib/python3.9/site-packages/pip/_internal/req/req_install.py\", line 867, in install\n",
            "    install_wheel(\n",
            "  File \"/Users/dietmarklotz/DataScience/TestAgenticAiCoursera/.venv/lib/python3.9/site-packages/pip/_internal/operations/install/wheel.py\", line 729, in install_wheel\n",
            "    _install_wheel(\n",
            "  File \"/Users/dietmarklotz/DataScience/TestAgenticAiCoursera/.venv/lib/python3.9/site-packages/pip/_internal/operations/install/wheel.py\", line 615, in _install_wheel\n",
            "    success = compileall.compile_file(path, force=True, quiet=True)\n",
            "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/compileall.py\", line 255, in compile_file\n",
            "    msg = err.msg.encode(sys.stdout.encoding,\n",
            "TypeError: encode() argument 'encoding' must be str, not None\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m43/44\u001b[0m [litellm]\n",
            "\u001b[1A\u001b[2KRequirement already satisfied: python-dotenv in ./.venv/lib/python3.9/site-packages (1.1.1)\n"
          ]
        }
      ],
      "source": [
        "#!pip install litellm\n",
        "#!pip install python-dotenv\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()  # Loads variables from .env into environment\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "if not api_key:\n",
        "    raise ValueError(\"OPENAI_API_KEY not found in .env file.\")\n",
        "os.environ['OPENAI_API_KEY'] = api_key # <---- Reference your OpenAI API key here\n",
        "\n",
        "# There are python files as examples in the /SamplePy directory.\n",
        "# There are sample data files in the /SampleData directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwe2eeOQB0cC",
        "outputId": "07254cd4-e623-4ec7-99bb-794b2f975d1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing: list_files with args {}\n",
            "Result: {'result': ['.DS_Store', 'Archive', 'SampleData', 'ASimpleAgentFramework.ipynb', 'README.md', '.gitignore', '.env', '.venv', 'SamplePy', '.git', 'AgentLoopWithFunctionCalling.ipynb']}\n",
            "Executing: list_directory_content with args {}\n",
            "Result: {'result': {'files': ['.DS_Store', 'ASimpleAgentFramework.ipynb', 'README.md', '.gitignore', '.env', 'AgentLoopWithFunctionCalling.ipynb'], 'directories': ['Archive', 'SampleData', '.venv', 'SamplePy', '.git']}}\n",
            "Executing: summarize_directory with args {'path': 'SampleData'}\n",
            "Result: {'result': {'SampleData/.DS_Store': \"Error reading/summarizing: 'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\", 'SampleData/Altertum.csv': 'The file lists various historical conflicts, including the Lagaš-Umma War, Akkad-Nagar and Akkad-Ebla War, Babylon-Mari War, the Battle of Megiddo, and the Battle of Qadeš, detailing their time frames, main aggressors, involved parties, and types of conflicts within the Near East region, although specific casualty figures are often not provided.', 'SampleData/Historical_Wildfires.csv': 'This dataset records various metrics related to fire incidents in New South Wales (NSW) from January 4th to January 14th, 2005, including estimated fire area, fire brightness, radiative power, and confidence levels, with all data entries marked as replaced (R).', 'SampleData/my_data1.db': \"Error reading/summarizing: 'utf-8' codec can't decode byte 0x82 in position 98: invalid start byte\"}}\n",
            "Termination message: The 'SampleData' folder contains a mix of files:\n",
            "\n",
            "1. **Altertum.csv**: Lists historical conflicts with details about time frames, aggressors, involved parties, and conflict types in the Near East region. \n",
            "2. **Historical_Wildfires.csv**: Records metrics related to fire incidents in New South Wales from January 4th to January 14th, 2005.\n",
            "3. **my_data1.db**: Unable to read, possibly a database file with non-text content.\n",
            "4. **.DS_Store**: Unable to read, likely a system file.\n",
            "\n",
            "If you need any specific data summarized or detailed, let me know!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "from typing import List\n",
        "\n",
        "from litellm import completion\n",
        "\n",
        "def list_files() -> List[str]:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    return os.listdir(\".\")\n",
        "\n",
        "#def list_files_recursive(path=\".\") -> list:\n",
        "#    \"\"\"List all files in the directory and subdirectories with their paths.\"\"\"\n",
        "#    file_list = []\n",
        "#    for root, dirs, files in os.walk(path):\n",
        "#        for file in files:\n",
        "#            file_list.append(os.path.join(root, file))\n",
        "#    return file_list\n",
        "\n",
        "def list_directory_content(path=\".\") -> dict:\n",
        "    \"\"\"List everything in current directory.\"\"\"\n",
        "    files = []\n",
        "    dirs = []\n",
        "    for entry in os.listdir(path):\n",
        "        if os.path.isfile(os.path.join(path, entry)):\n",
        "            files.append(entry)\n",
        "        elif os.path.isdir(os.path.join(path, entry)):\n",
        "            dirs.append(entry)\n",
        "    return {\"files\": files, \"directories\": dirs}\n",
        "\n",
        "def summarize_directory(path=\".\") -> dict:\n",
        "    \"\"\"Summarize what each file in the directory and subdirectories is about, including file paths.\"\"\"\n",
        "    summaries = {}\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            full_path = os.path.join(root, file)\n",
        "            try:\n",
        "                with open(full_path, \"r\") as f:\n",
        "                    content = f.read(1000)  # Read first 1000 chars for summary\n",
        "                # Use LLM to summarize\n",
        "                summary_response = completion(\n",
        "                    model=\"openai/gpt-4o\",\n",
        "                    messages=[\n",
        "                        {\"role\": \"system\", \"content\": \"Summarize the following file content in 1-2 sentences.\"},\n",
        "                        {\"role\": \"user\", \"content\": content}\n",
        "                    ],\n",
        "                    max_tokens=100\n",
        "                )\n",
        "                summary = summary_response.choices[0].message.content.strip()\n",
        "            except Exception as e:\n",
        "                summary = f\"Error reading/summarizing: {str(e)}\"\n",
        "            summaries[full_path] = summary\n",
        "    return summaries\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read a file's contents.\"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def terminate(message: str) -> None:\n",
        "    \"\"\"Terminate the agent loop and provide a summary message.\"\"\"\n",
        "    print(f\"Termination message: {message}\")\n",
        "\n",
        "tool_functions = {\n",
        "    \"list_files\": list_files,\n",
        "    #\"list_files_recursive\": list_files_recursive,\n",
        "    \"list_directory_content\": list_directory_content,\n",
        "    \"summarize_directory\": summarize_directory, \n",
        "    \"read_file\": read_file,\n",
        "    \"terminate\": terminate\n",
        "}\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"list_files\",\n",
        "            \"description\": \"Returns a list of files in the directory.\",\n",
        "            \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
        "        }\n",
        "    },\n",
        "        #{\n",
        "        #\"type\": \"function\",\n",
        "        #\"function\": {\n",
        "        #    \"name\": \"list_files_recursive\",\n",
        "        #    \"description\": \"Returns a list of files in the directory and sub directories with their paths.\",\n",
        "        #    \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
        "        #}\n",
        "    #},\n",
        "        {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"list_directory_content\",\n",
        "            \"description\": \"Returns the content of the current directory.\",\n",
        "            \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
        "        }\n",
        "    },\n",
        "        {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"summarize_directory\",\n",
        "            \"description\": \"Returns a summary of the content in specified directory.\",\n",
        "            \"parameters\": {\n",
        "                 \"type\": \"object\",\n",
        "                 \"properties\": {\n",
        "                    \"path\": {\"type\": \"string\", \"description\": \"The directory path to summarize.\"}\n",
        "                    },\n",
        "                \"required\": [\"path\"]\n",
        "             }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"read_file\",\n",
        "            \"description\": \"Reads the content of a specified file in the directory.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "                \"required\": [\"file_name\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"terminate\",\n",
        "            \"description\": \"Terminates the conversation. No further actions or interactions are possible after this. Prints the provided message for the user.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"message\": {\"type\": \"string\"},\n",
        "                },\n",
        "                \"required\": [\"message\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "If a user asks about files, documents, or content, first list the files before reading them.\n",
        "\n",
        "When you are done, terminate the conversation by using the \"terminate\" tool and I will provide the results to the user.\n",
        "\"\"\"\n",
        "}]\n",
        "\n",
        "# Initialize agent parameters\n",
        "iterations = 0\n",
        "max_iterations = 10\n",
        "\n",
        "user_task = input(\"What would you like me to do? \")\n",
        "\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "\n",
        "# The Agent Loop\n",
        "while iterations < max_iterations:\n",
        "\n",
        "    messages = agent_rules + memory\n",
        "    iterations += 1\n",
        "\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "\n",
        "    if response.choices[0].message.tool_calls:\n",
        "        tool = response.choices[0].message.tool_calls[0]\n",
        "        tool_name = tool.function.name\n",
        "        tool_args = json.loads(tool.function.arguments)\n",
        "\n",
        "        action = {\n",
        "            \"tool_name\": tool_name,\n",
        "            \"args\": tool_args\n",
        "        }\n",
        "\n",
        "        if tool_name == \"terminate\":\n",
        "            print(f\"Termination message: {tool_args['message']}\")\n",
        "            break\n",
        "        elif tool_name in tool_functions:\n",
        "            try:\n",
        "                result = {\"result\": tool_functions[tool_name](**tool_args)}\n",
        "            except Exception as e:\n",
        "                result = {\"error\":f\"Error executing {tool_name}: {str(e)}\"}\n",
        "        else:\n",
        "            result = {\"error\": f\"Unknown tool: {tool_name}\"}\n",
        "\n",
        "        print(f\"Executing: {tool_name} with args {tool_args}\")\n",
        "        print(f\"Result: {result}\")\n",
        "        memory.extend([\n",
        "            {\"role\": \"assistant\", \"content\": json.dumps(action)},\n",
        "            {\"role\": \"user\", \"content\": json.dumps(result)}\n",
        "        ])\n",
        "    else:\n",
        "        result = response.choices[0].message.content\n",
        "        print(f\"Response: {result}\")\n",
        "        break\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
